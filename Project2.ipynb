{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMDl-KFaxgRT"
      },
      "source": [
        "# Project 2 Computer Vision CS-GY 6643\n",
        "Team Members:\n",
        "- Diego Rosenebrg (dr3432)\n",
        "- Thiago Viegas (tjv235)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ggHieUmxc6Z"
      },
      "source": [
        "## Question 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7xXgztZNue8"
      },
      "source": [
        "We will keep the original model (provided to us by the TAs) as a sanity check and a base resource to base ourselves off of. We will begin our own improved version of this in the \"Team Model\" subsection below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jHjOxmOV2i_"
      },
      "source": [
        "## General Q5 Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLkIsu5cvrbY"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'chmod' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "# Get google colab private keys\n",
        "import os\n",
        "import json\n",
        "kaggle_username = \"thiagoviegas\"\n",
        "api_key = '---' # Make sure to have KAGGLE_API name in google colab secret keys\n",
        "\n",
        "# Dictionary of username, and key\n",
        "kaggle_dict = {'username': kaggle_username, 'key': api_key}\n",
        "\n",
        "# Check if \"~/.kaggle/\" folder exists\n",
        "if not os.path.exists(os.path.expanduser(\"~/.kaggle\")):\n",
        "    os.makedirs(os.path.expanduser(\"~/.kaggle\"))\n",
        "\n",
        "# Save kaggle_dict to \"~/.kaggle/kaggle.json\"\n",
        "with open(os.path.expanduser(\"~/.kaggle/kaggle.json\"), 'w') as f:\n",
        "    json.dump(kaggle_dict, f)\n",
        "\n",
        "# chmod 600 the kaggle.json file\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrQ2vOfnw98r",
        "outputId": "9a3ced22-d41a-4239-f0a2-4a17d78da67d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'kaggle' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c cell-segmentation-cs-gy-6643\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xn_ujDW1kfiJ",
        "outputId": "f74fa734-4c8e-4971-8ece-e5cc088124fd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'kaggle' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions list | head\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OshINFqHkJa6",
        "outputId": "2b4b341a-1b83-47d8-c9eb-6ae62c292d59"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'ls' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!ls -lh /content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npCRuw19xlsJ",
        "outputId": "2eef5205-8aab-44f3-c860-28c8be6d8fe6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'unzip' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'ls' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "# Unzip the competition archive again into data_folder/\n",
        "!unzip -q cell-segmentation-cs-gy-6643.zip -d data_folder\n",
        "\n",
        "# Quick check: list top-level contents\n",
        "!ls -lh data_folder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python = c:\\Python312\\python.exe\n",
            "torch.__version__ = 2.6.0+cu124\n",
            "torch.version.cuda = 12.4\n",
            "cuda available     = True\n",
            "NVIDIA GeForce RTX 4070\n"
          ]
        }
      ],
      "source": [
        "import sys, torch\n",
        "print(\"python =\", sys.executable)\n",
        "print(\"torch.__version__ =\", torch.__version__)\n",
        "print(\"torch.version.cuda =\", torch.version.cuda)   # expect '12.4'\n",
        "print(\"cuda available     =\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(torch.cuda.get_device_name(0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4LtPAfsyk5l",
        "outputId": "037d7786-18dd-4f2a-e10f-77ba9a89d165"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12.4\n",
            "True\n",
            "Device: cuda\n",
            "CUDA build present?   True\n",
            "torch.__version__ = 2.6.0+cu124\n"
          ]
        }
      ],
      "source": [
        "import os, cv2, math, xml.etree.ElementTree as ET\n",
        "import numpy as np, pandas as pd\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pathlib import Path\n",
        "from skimage import draw\n",
        "from skimage.measure import label as cc_label\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Paths (you already unzipped to data_folder)\n",
        "BASE = Path(\"data_folder\")\n",
        "TRAIN_DIR = BASE / \"train\"\n",
        "TEST_DIR  = BASE / \"test_final\"\n",
        "\n",
        "CLASSES = [\"Epithelial\",\"Lymphocyte\",\"Neutrophil\",\"Macrophage\"]\n",
        "IMG_SIZE = 320        # small & fast; bump for quality\n",
        "BATCH_SIZE = 4\n",
        "EPOCHS = 3            # quick demo; bump to 15â€“30 for results\n",
        "LR = 1e-3\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torch\n",
        "print(torch.version.cuda)\n",
        "print(torch.cuda.is_available())\n",
        "print(\"Device:\", DEVICE)\n",
        "print(\"CUDA build present?  \", torch.backends.cuda.is_built())\n",
        "print(\"torch.__version__ =\", torch.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "W6TTcUC7zwDu"
      },
      "outputs": [],
      "source": [
        "def parse_xml(xml_path):\n",
        "    tree = ET.parse(xml_path)\n",
        "    root = tree.getroot()\n",
        "    annotations = []\n",
        "\n",
        "    for annotation in root.findall('Annotation'):\n",
        "        cell_type = None\n",
        "        attributes = annotation.find('Attributes')\n",
        "        if attributes is not None:\n",
        "            attribute = attributes.find('Attribute')\n",
        "            if attribute is not None:\n",
        "                cell_type = attribute.get('Name')\n",
        "\n",
        "        if not cell_type:\n",
        "            continue\n",
        "\n",
        "        regions_element = annotation.find('Regions')\n",
        "        if regions_element is not None:\n",
        "            regions = regions_element.findall('Region')\n",
        "\n",
        "            for region in regions:\n",
        "                vertices = []\n",
        "                vertices_element = region.find('Vertices')\n",
        "\n",
        "                if vertices_element is not None:\n",
        "                    for vertex in vertices_element.findall('Vertex'):\n",
        "                        x = float(vertex.get('X'))\n",
        "                        y = float(vertex.get('Y'))\n",
        "                        vertices.append((x, y))\n",
        "\n",
        "                if vertices:\n",
        "                    annotations.append({\n",
        "                        'cell_type': cell_type,\n",
        "                        'vertices': vertices\n",
        "                    })\n",
        "\n",
        "    return annotations\n",
        "\n",
        "def generate_masks(image_shape, annotations):\n",
        "    height, width = image_shape[:2]\n",
        "\n",
        "    masks = {\n",
        "        'Epithelial': np.zeros((height, width), dtype=np.uint16),\n",
        "        'Lymphocyte': np.zeros((height, width), dtype=np.uint16),\n",
        "        'Neutrophil': np.zeros((height, width), dtype=np.uint16),\n",
        "        'Macrophage': np.zeros((height, width), dtype=np.uint16)\n",
        "    }\n",
        "\n",
        "    instance_id = {\n",
        "        'Epithelial': 1,\n",
        "        'Lymphocyte': 1,\n",
        "        'Neutrophil': 1,\n",
        "        'Macrophage': 1\n",
        "    }\n",
        "\n",
        "    for ann in annotations:\n",
        "        cell_type = ann['cell_type']\n",
        "        if cell_type in masks:\n",
        "            vertices = np.array(ann['vertices'])\n",
        "            rr, cc = draw.polygon(vertices[:, 1], vertices[:, 0], shape=(height, width))\n",
        "            masks[cell_type][rr, cc] = instance_id[cell_type]\n",
        "            instance_id[cell_type] += 1\n",
        "\n",
        "    return masks\n",
        "\n",
        "def rle_encode(mask):\n",
        "    pixels = mask.flatten(order=\"F\").astype(np.int32)\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "\n",
        "    rle_parts = []\n",
        "    for i in range(len(runs)-1):\n",
        "        start = runs[i]\n",
        "        end = runs[i+1] if i+1 < len(runs) else len(pixels)-1\n",
        "        length = end - start\n",
        "        value = pixels[start]\n",
        "\n",
        "        if value > 0:\n",
        "            rle_parts.extend([value, start, length])\n",
        "\n",
        "    return ' '.join(str(x) for x in rle_parts) if rle_parts else \"\"\n",
        "\n",
        "def rle_decode(mask_rle, shape):\n",
        "    if isinstance(mask_rle, float) and np.isnan(mask_rle):\n",
        "        return np.zeros(shape, dtype=np.uint16)\n",
        "\n",
        "    if not mask_rle or mask_rle.strip() == '':\n",
        "        return np.zeros(shape, dtype=np.uint16)\n",
        "\n",
        "    s = str(mask_rle).split()\n",
        "    if len(s) == 0 or len(s) % 3 != 0:\n",
        "        return np.zeros(shape, dtype=np.uint16)\n",
        "\n",
        "    img = np.zeros(shape[0] * shape[1], dtype=np.uint16)\n",
        "\n",
        "    for i in range(0, len(s), 3):\n",
        "        value = int(s[i])\n",
        "        start = int(s[i+1]) - 1\n",
        "        length = int(s[i+2])\n",
        "        img[start:start+length] = value\n",
        "\n",
        "    return img.reshape(shape, order='F')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Thiago Model starts here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "from torchvision.transforms import functional as TF\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "I1zhU8fZ5xZN"
      },
      "outputs": [],
      "source": [
        "class CellMaskDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      image: Tensor[C,H,W] (float 0..1)\n",
        "      target: dict with keys:\n",
        "        'boxes': FloatTensor[N,4] in (x1,y1,x2,y2)\n",
        "        'labels': Int64Tensor[N] in 1..num_classes\n",
        "        'masks': UInt8Tensor[N,H,W] binary masks (0/1)\n",
        "        'image_id': Int64Tensor[1]\n",
        "        'area': FloatTensor[N]\n",
        "        'iscrowd': Int64Tensor[N] (usually zeros)\n",
        "    \"\"\"\n",
        "    def __init__(self, data_dir, classes=CLASSES, transforms=None):\n",
        "        self.data_dir = Path(data_dir)\n",
        "        self.xml_files = list(self.data_dir.glob(\"*.xml\"))\n",
        "        self.classes = classes\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.xml_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        xml_path = self.xml_files[idx]\n",
        "        img_path = xml_path.with_suffix('.tif')\n",
        "        image = cv2.imread(str(img_path))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        H, W = image.shape[:2]\n",
        "\n",
        "        # parse XML and get per-class instance map (uint16, different ints for instances)\n",
        "        annotations = parse_xml(xml_path)\n",
        "        masks_by_class = generate_masks((H, W, 3), annotations)  # same function you have\n",
        "\n",
        "        masks_list = []\n",
        "        boxes = []\n",
        "        labels = []\n",
        "        areas = []\n",
        "        iscrowd = []\n",
        "\n",
        "        for cls_idx, cls_name in enumerate(self.classes):\n",
        "            inst_map = masks_by_class[cls_name]  # uint16 array, 0=background\n",
        "            unique_ids = np.unique(inst_map)\n",
        "            unique_ids = unique_ids[unique_ids != 0]\n",
        "            for inst_id in unique_ids:\n",
        "                bin_mask = (inst_map == inst_id).astype(np.uint8)\n",
        "                # compute bbox (x1,y1,x2,y2)\n",
        "                ys, xs = np.where(bin_mask)\n",
        "                if len(xs) == 0 or len(ys) == 0:\n",
        "                    continue\n",
        "                x1 = float(xs.min())\n",
        "                x2 = float(xs.max())\n",
        "                y1 = float(ys.min())\n",
        "                y2 = float(ys.max())\n",
        "                boxes.append([x1, y1, x2, y2])\n",
        "                masks_list.append(bin_mask)\n",
        "                labels.append(cls_idx + 1)  # 1-based labels\n",
        "                areas.append(float(bin_mask.sum()))\n",
        "                iscrowd.append(0)\n",
        "\n",
        "        if len(boxes) == 0:\n",
        "            # return empty target (valid form)\n",
        "            boxes = torch.zeros((0,4), dtype=torch.float32)\n",
        "            labels = torch.zeros((0,), dtype=torch.int64)\n",
        "            masks = torch.zeros((0, H, W), dtype=torch.uint8)\n",
        "            areas = torch.zeros((0,), dtype=torch.float32)\n",
        "            iscrowd = torch.zeros((0,), dtype=torch.int64)\n",
        "        else:\n",
        "            boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "            labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "            masks = torch.as_tensor(np.stack(masks_list, axis=0), dtype=torch.uint8)\n",
        "            areas = torch.as_tensor(areas, dtype=torch.float32)\n",
        "            iscrowd = torch.as_tensor(iscrowd, dtype=torch.int64)\n",
        "\n",
        "        image_tensor = TF.to_tensor(image)  # converts to float tensor C,H,W scaled 0..1\n",
        "\n",
        "        target = {\n",
        "            \"boxes\": boxes,\n",
        "            \"labels\": labels,\n",
        "            \"masks\": masks,\n",
        "            \"image_id\": torch.tensor([idx]),\n",
        "            \"area\": areas,\n",
        "            \"iscrowd\": iscrowd\n",
        "        }\n",
        "\n",
        "        if self.transforms:\n",
        "            image_tensor, target = self.transforms(image_tensor, target)\n",
        "\n",
        "        return image_tensor, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    images, targets = zip(*batch)\n",
        "    return list(images), list(targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_maskrcnn_model(num_classes):\n",
        "    # num_classes includes background (so 5 for 4 cell types + bg)\n",
        "    model = maskrcnn_resnet50_fpn(pretrained=True)\n",
        "    # replace the box predictor\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "    # replace the mask predictor\n",
        "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "    hidden_layer = 256\n",
        "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\thiag\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "C:\\Users\\thiag\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MaskRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\" to C:\\Users\\thiag/.cache\\torch\\hub\\checkpoints\\maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170M/170M [00:02<00:00, 72.7MB/s] \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MaskRCNN(\n",
              "  (transform): GeneralizedRCNNTransform(\n",
              "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
              "  )\n",
              "  (backbone): BackboneWithFPN(\n",
              "    (body): IntermediateLayerGetter(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (layer1): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (fpn): FeaturePyramidNetwork(\n",
              "      (inner_blocks): ModuleList(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (layer_blocks): ModuleList(\n",
              "        (0-3): 4 x Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (extra_blocks): LastLevelMaxPool()\n",
              "    )\n",
              "  )\n",
              "  (rpn): RegionProposalNetwork(\n",
              "    (anchor_generator): AnchorGenerator()\n",
              "    (head): RPNHead(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (roi_heads): RoIHeads(\n",
              "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
              "    (box_head): TwoMLPHead(\n",
              "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
              "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    )\n",
              "    (box_predictor): FastRCNNPredictor(\n",
              "      (cls_score): Linear(in_features=1024, out_features=5, bias=True)\n",
              "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
              "    )\n",
              "    (mask_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(14, 14), sampling_ratio=2)\n",
              "    (mask_head): MaskRCNNHeads(\n",
              "      (0): Conv2dNormActivation(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (1): Conv2dNormActivation(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Conv2dNormActivation(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Conv2dNormActivation(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (mask_predictor): MaskRCNNPredictor(\n",
              "      (conv5_mask): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (mask_fcn_logits): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "NUM_CLASSES = len(CLASSES) + 1  # +1 for background\n",
        "model = get_maskrcnn_model(NUM_CLASSES)\n",
        "model.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10):\n",
        "    model.train()\n",
        "    for i, (images, targets) in enumerate(data_loader):\n",
        "        images = [img.to(device) for img in images]\n",
        "        targets = [{k: v.to(device) for k,v in t.items()} for t in targets]\n",
        "        loss_dict = model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i % print_freq == 0:\n",
        "            print(f\"Epoch {epoch} Iter {i}/{len(data_loader)} loss: {losses.item():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 Iter 0/105 loss: 12.3742\n",
            "Epoch 0 Iter 10/105 loss: 2.6552\n",
            "Epoch 0 Iter 20/105 loss: 1.6628\n",
            "Epoch 0 Iter 30/105 loss: 2.3485\n",
            "Epoch 0 Iter 40/105 loss: 2.1138\n",
            "Epoch 0 Iter 50/105 loss: 1.4654\n",
            "Epoch 0 Iter 60/105 loss: 0.9454\n",
            "Epoch 0 Iter 70/105 loss: 2.0101\n",
            "Epoch 0 Iter 80/105 loss: 1.4931\n",
            "Epoch 0 Iter 90/105 loss: 1.3993\n",
            "Epoch 0 Iter 100/105 loss: 1.3598\n",
            "Epoch 1 Iter 0/105 loss: 1.1111\n",
            "Epoch 1 Iter 10/105 loss: 0.8749\n",
            "Epoch 1 Iter 20/105 loss: 0.9713\n",
            "Epoch 1 Iter 30/105 loss: 0.9975\n",
            "Epoch 1 Iter 40/105 loss: 1.4131\n",
            "Epoch 1 Iter 50/105 loss: 0.8740\n",
            "Epoch 1 Iter 60/105 loss: 0.8430\n",
            "Epoch 1 Iter 70/105 loss: 1.1199\n",
            "Epoch 1 Iter 80/105 loss: 0.8735\n",
            "Epoch 1 Iter 90/105 loss: 1.1955\n",
            "Epoch 1 Iter 100/105 loss: 0.9313\n",
            "Epoch 2 Iter 0/105 loss: 1.1252\n",
            "Epoch 2 Iter 10/105 loss: 1.2139\n",
            "Epoch 2 Iter 20/105 loss: 1.3987\n",
            "Epoch 2 Iter 30/105 loss: 0.9140\n",
            "Epoch 2 Iter 40/105 loss: 0.7758\n",
            "Epoch 2 Iter 50/105 loss: 1.6176\n",
            "Epoch 2 Iter 60/105 loss: 0.8254\n",
            "Epoch 2 Iter 70/105 loss: 1.2198\n",
            "Epoch 2 Iter 80/105 loss: 0.6268\n",
            "Epoch 2 Iter 90/105 loss: 0.9662\n",
            "Epoch 2 Iter 100/105 loss: 0.9113\n",
            "Epoch 3 Iter 0/105 loss: 0.9046\n",
            "Epoch 3 Iter 10/105 loss: 0.9079\n",
            "Epoch 3 Iter 20/105 loss: 1.0294\n",
            "Epoch 3 Iter 30/105 loss: 0.7331\n",
            "Epoch 3 Iter 40/105 loss: 1.1023\n",
            "Epoch 3 Iter 50/105 loss: 0.8278\n",
            "Epoch 3 Iter 60/105 loss: 0.8556\n",
            "Epoch 3 Iter 70/105 loss: 0.6837\n",
            "Epoch 3 Iter 80/105 loss: 0.7837\n",
            "Epoch 3 Iter 90/105 loss: 0.7083\n",
            "Epoch 3 Iter 100/105 loss: 1.0562\n",
            "Epoch 4 Iter 0/105 loss: 0.8560\n",
            "Epoch 4 Iter 10/105 loss: 0.9950\n",
            "Epoch 4 Iter 20/105 loss: 0.6242\n",
            "Epoch 4 Iter 30/105 loss: 0.5839\n",
            "Epoch 4 Iter 40/105 loss: 0.6281\n",
            "Epoch 4 Iter 50/105 loss: 0.5800\n",
            "Epoch 4 Iter 60/105 loss: 0.7883\n",
            "Epoch 4 Iter 70/105 loss: 0.6366\n",
            "Epoch 4 Iter 80/105 loss: 0.6379\n",
            "Epoch 4 Iter 90/105 loss: 1.0025\n",
            "Epoch 4 Iter 100/105 loss: 1.0751\n",
            "Epoch 5 Iter 0/105 loss: 0.8163\n",
            "Epoch 5 Iter 10/105 loss: 0.7352\n",
            "Epoch 5 Iter 20/105 loss: 0.7910\n",
            "Epoch 5 Iter 30/105 loss: 0.8697\n",
            "Epoch 5 Iter 40/105 loss: 0.7396\n",
            "Epoch 5 Iter 50/105 loss: 0.7744\n",
            "Epoch 5 Iter 60/105 loss: 0.7008\n",
            "Epoch 5 Iter 70/105 loss: 0.8122\n",
            "Epoch 5 Iter 80/105 loss: 0.5637\n",
            "Epoch 5 Iter 90/105 loss: 0.6961\n",
            "Epoch 5 Iter 100/105 loss: 0.7521\n",
            "Epoch 6 Iter 0/105 loss: 0.5646\n",
            "Epoch 6 Iter 10/105 loss: 0.8634\n",
            "Epoch 6 Iter 20/105 loss: 0.8030\n",
            "Epoch 6 Iter 30/105 loss: 0.6030\n",
            "Epoch 6 Iter 40/105 loss: 0.7902\n",
            "Epoch 6 Iter 50/105 loss: 0.8642\n",
            "Epoch 6 Iter 60/105 loss: 0.6957\n",
            "Epoch 6 Iter 70/105 loss: 0.9196\n",
            "Epoch 6 Iter 80/105 loss: 0.6393\n",
            "Epoch 6 Iter 90/105 loss: 0.7919\n",
            "Epoch 6 Iter 100/105 loss: 0.7101\n",
            "Epoch 7 Iter 0/105 loss: 0.5813\n",
            "Epoch 7 Iter 10/105 loss: 0.7237\n",
            "Epoch 7 Iter 20/105 loss: 0.3636\n",
            "Epoch 7 Iter 30/105 loss: 0.9568\n",
            "Epoch 7 Iter 40/105 loss: 0.5197\n",
            "Epoch 7 Iter 50/105 loss: 0.5580\n",
            "Epoch 7 Iter 60/105 loss: 1.0129\n",
            "Epoch 7 Iter 70/105 loss: 0.9903\n",
            "Epoch 7 Iter 80/105 loss: 1.0412\n",
            "Epoch 7 Iter 90/105 loss: 0.5988\n",
            "Epoch 7 Iter 100/105 loss: 0.9050\n",
            "Epoch 8 Iter 0/105 loss: 0.2878\n",
            "Epoch 8 Iter 10/105 loss: 0.5985\n",
            "Epoch 8 Iter 20/105 loss: 0.6470\n",
            "Epoch 8 Iter 30/105 loss: 0.7842\n",
            "Epoch 8 Iter 40/105 loss: 0.7546\n",
            "Epoch 8 Iter 50/105 loss: 0.4254\n",
            "Epoch 8 Iter 60/105 loss: 0.6568\n",
            "Epoch 8 Iter 70/105 loss: 0.3525\n",
            "Epoch 8 Iter 80/105 loss: 0.9426\n",
            "Epoch 8 Iter 90/105 loss: 0.7914\n",
            "Epoch 8 Iter 100/105 loss: 0.6063\n",
            "Epoch 9 Iter 0/105 loss: 0.7219\n",
            "Epoch 9 Iter 10/105 loss: 0.5109\n",
            "Epoch 9 Iter 20/105 loss: 0.8084\n",
            "Epoch 9 Iter 30/105 loss: 0.9579\n",
            "Epoch 9 Iter 40/105 loss: 0.7485\n",
            "Epoch 9 Iter 50/105 loss: 0.8624\n",
            "Epoch 9 Iter 60/105 loss: 0.5175\n",
            "Epoch 9 Iter 70/105 loss: 0.2844\n",
            "Epoch 9 Iter 80/105 loss: 0.6951\n",
            "Epoch 9 Iter 90/105 loss: 0.4963\n",
            "Epoch 9 Iter 100/105 loss: 0.4966\n"
          ]
        }
      ],
      "source": [
        "dataset = CellMaskDataset(TRAIN_DIR, classes=CLASSES)\n",
        "train_loader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=0, collate_fn=collate_fn)\n",
        "\n",
        "model = get_maskrcnn_model(NUM_CLASSES).to(DEVICE)\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "NUM_EPOCHS = 30\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_one_epoch(model, optimizer, train_loader, DEVICE, epoch)\n",
        "    torch.save(model.state_dict(), f\"maskrcnn_epoch_{epoch+1}.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def masks_to_class_instance_map(pred_boxes, pred_labels, pred_scores, pred_masks, image_shape, score_threshold=0.5):\n",
        "    \"\"\"\n",
        "    pred_masks: Tensor[N, 1, H, W] or (N, H, W) depending on torchvision version\n",
        "    returns dict: {class_name: labeled_mask_uint16}, where each pixel value is instance id (1..K)\n",
        "    \"\"\"\n",
        "    H, W = image_shape\n",
        "    per_class_map = {cls: np.zeros((H, W), dtype=np.uint16) for cls in CLASSES}\n",
        "    # adjust masks shape if needed\n",
        "    if pred_masks.dim() == 4:\n",
        "        pred_masks = pred_masks.squeeze(1)  # (N, H, W)\n",
        "    N = pred_masks.shape[0]\n",
        "    instance_counters = {cls: 1 for cls in CLASSES}\n",
        "\n",
        "    for i in range(N):\n",
        "        score = float(pred_scores[i].cpu().numpy())\n",
        "        if score < score_threshold:\n",
        "            continue\n",
        "        lbl = int(pred_labels[i].cpu().numpy())  # 1..num_classes-1\n",
        "        if lbl == 0:\n",
        "            continue\n",
        "        cls_name = CLASSES[lbl-1]\n",
        "        mask_prob = pred_masks[i].cpu().numpy()\n",
        "        bin_mask = (mask_prob > 0.5).astype(np.uint8)\n",
        "        if bin_mask.sum() == 0:\n",
        "            continue\n",
        "        inst_id = instance_counters[cls_name]\n",
        "        per_class_map[cls_name][bin_mask == 1] = inst_id\n",
        "        instance_counters[cls_name] += 1\n",
        "\n",
        "    return per_class_map\n",
        "\n",
        "# Example inference on single image:\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    img = cv2.imread(str(TEST_DIR / \"slide1.tif\"))\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img_tensor = TF.to_tensor(img_rgb).to(DEVICE)\n",
        "    outputs = model([img_tensor])[0]\n",
        "    per_class_maps = masks_to_class_instance_map(outputs['boxes'], outputs['labels'], outputs['scores'], outputs['masks'], image_shape=img_rgb.shape[:2], score_threshold=0.5)\n",
        "\n",
        "# Convert per_class_maps to your RLE format using your rle_encode\n",
        "submission_row = {'image_id': 'slide1'}\n",
        "for cls in CLASSES:\n",
        "    mask = per_class_maps[cls]  # uint16 array with instance ids\n",
        "    submission_row[cls] = rle_encode(mask) if mask.max() > 0 else \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_maskrcnn_test_set(model, test_dir, device, score_thresh=0.5, mask_thresh=0.5, resize_to=None):\n",
        "    \"\"\"\n",
        "    Run Mask R-CNN on test images and produce a DataFrame like your submission format:\n",
        "      columns = ['image_id', 'Epithelial', 'Lymphocyte', 'Neutrophil', 'Macrophage']\n",
        "\n",
        "    Args:\n",
        "      model: Mask R-CNN (already loaded & in eval mode).\n",
        "      test_dir: path-like to folder with .tif test images (use TEST_DIR).\n",
        "      device: 'cuda' or 'cpu'.\n",
        "      score_thresh: min detection score to keep instance.\n",
        "      mask_thresh: threshold to binarize predicted mask probs.\n",
        "      resize_to: if model was trained on resized images, pass int (e.g., IMG_SIZE). If None, predicts at original size.\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    test_tif_files = list(Path(test_dir).glob(\"*.tif\"))\n",
        "    rows = []\n",
        "\n",
        "    for tif_file in tqdm(test_tif_files, desc=\"Predicting test images\"):\n",
        "        img = cv2.imread(str(tif_file))\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        orig_h, orig_w = img_rgb.shape[:2]\n",
        "\n",
        "        # Prepare input tensor (optionally resize to model input size)\n",
        "        if resize_to is not None:\n",
        "            img_in = cv2.resize(img_rgb, (resize_to, resize_to))\n",
        "        else:\n",
        "            img_in = img_rgb\n",
        "\n",
        "        img_tensor = TF.to_tensor(img_in).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model([img_tensor])[0]\n",
        "\n",
        "        # outputs: dict with keys 'boxes','labels','scores','masks'\n",
        "        masks = outputs.get('masks')          # Tensor [N,1,H,W] or [N,H,W] depending on torchvision\n",
        "        labels = outputs.get('labels')        # Tensor [N]\n",
        "        scores = outputs.get('scores')        # Tensor [N]\n",
        "\n",
        "        # Ensure masks shape is [N, H, W]\n",
        "        if masks is None:\n",
        "            # No masks predicted\n",
        "            per_class_map = {c: np.zeros((orig_h, orig_w), dtype=np.uint16) for c in CLASSES}\n",
        "        else:\n",
        "            if masks.ndim == 4:\n",
        "                masks = masks.squeeze(1)      # -> [N, H, W]\n",
        "\n",
        "            N = masks.shape[0]\n",
        "            per_class_map = {c: np.zeros((orig_h, orig_w), dtype=np.uint16) for c in CLASSES}\n",
        "            inst_counters = {c: 1 for c in CLASSES}\n",
        "\n",
        "            for i in range(N):\n",
        "                score = float(scores[i].cpu().item())\n",
        "                if score < score_thresh:\n",
        "                    continue\n",
        "\n",
        "                label = int(labels[i].cpu().item())   # 1..num_classes-1\n",
        "                if label == 0:\n",
        "                    continue\n",
        "                cls_name = CLASSES[label - 1]\n",
        "\n",
        "                mask_prob = masks[i].cpu().numpy()\n",
        "                # If we resized input for the model, resize mask back to original image size\n",
        "                if resize_to is not None and (mask_prob.shape[0] != orig_h or mask_prob.shape[1] != orig_w):\n",
        "                    mask_prob = cv2.resize(mask_prob, (orig_w, orig_h))  # note width,height order\n",
        "\n",
        "                bin_mask = (mask_prob > mask_thresh).astype(np.uint8)\n",
        "                if bin_mask.sum() == 0:\n",
        "                    continue\n",
        "\n",
        "                inst_id = inst_counters[cls_name]\n",
        "                per_class_map[cls_name][bin_mask == 1] = inst_id\n",
        "                inst_counters[cls_name] += 1\n",
        "\n",
        "        # Build a submission row\n",
        "        image_id = tif_file.stem\n",
        "        row = {'image_id': image_id}\n",
        "        for cls in CLASSES:\n",
        "            mask = per_class_map[cls]\n",
        "            rle = rle_encode(mask) if mask.max() > 0 else \"\"\n",
        "            # following your notebook convention: convert empty to 0\n",
        "            if not rle:\n",
        "                rle = 0\n",
        "            row[cls] = rle\n",
        "\n",
        "        rows.append(row)\n",
        "\n",
        "    return pd.DataFrame(rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MaskRCNN(\n",
              "  (transform): GeneralizedRCNNTransform(\n",
              "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
              "  )\n",
              "  (backbone): BackboneWithFPN(\n",
              "    (body): IntermediateLayerGetter(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (layer1): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (fpn): FeaturePyramidNetwork(\n",
              "      (inner_blocks): ModuleList(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (layer_blocks): ModuleList(\n",
              "        (0-3): 4 x Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (extra_blocks): LastLevelMaxPool()\n",
              "    )\n",
              "  )\n",
              "  (rpn): RegionProposalNetwork(\n",
              "    (anchor_generator): AnchorGenerator()\n",
              "    (head): RPNHead(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (roi_heads): RoIHeads(\n",
              "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
              "    (box_head): TwoMLPHead(\n",
              "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
              "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    )\n",
              "    (box_predictor): FastRCNNPredictor(\n",
              "      (cls_score): Linear(in_features=1024, out_features=5, bias=True)\n",
              "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
              "    )\n",
              "    (mask_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(14, 14), sampling_ratio=2)\n",
              "    (mask_head): MaskRCNNHeads(\n",
              "      (0): Conv2dNormActivation(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (1): Conv2dNormActivation(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Conv2dNormActivation(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Conv2dNormActivation(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (mask_predictor): MaskRCNNPredictor(\n",
              "      (conv5_mask): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (mask_fcn_logits): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Recreate model architecture and load checkpoint\n",
        "NUM_CLASSES = len(CLASSES) + 1\n",
        "model = get_maskrcnn_model(NUM_CLASSES)  # use the same function you used for training\n",
        "checkpoint_path = \"maskrcnn_epoch_10.pth\"    # change to your saved .pth\n",
        "model.load_state_dict(torch.load(checkpoint_path, map_location=DEVICE))\n",
        "model.to(DEVICE)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting test images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:07<00:00,  5.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved submission.csv â€” shape: (40, 5)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>Epithelial</th>\n",
              "      <th>Lymphocyte</th>\n",
              "      <th>Neutrophil</th>\n",
              "      <th>Macrophage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>slide1</td>\n",
              "      <td>0</td>\n",
              "      <td>1 31277 7 1 31432 11 1 31588 13 1 31744 15 1 3...</td>\n",
              "      <td>0</td>\n",
              "      <td>2 1850 16 2 2006 19 2 2161 22 2 2317 24 2 2472...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>slide2</td>\n",
              "      <td>1 65184 4 1 66132 7 1 67081 9 1 68030 11 1 689...</td>\n",
              "      <td>57 1540 9 57 2488 13 57 3437 15 34 4278 6 57 4...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>slide3</td>\n",
              "      <td>0</td>\n",
              "      <td>91 3209 7 91 3774 11 91 4340 12 91 4906 14 91 ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>slide4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1 1524 6 1 1656 10 1 1787 15 1 1919 19 1 2051 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>slide5</td>\n",
              "      <td>76 13348 16 76 15496 21 76 17645 24 76 19795 2...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   image_id                                         Epithelial  \\\n",
              "0    slide1                                                  0   \n",
              "11   slide2  1 65184 4 1 66132 7 1 67081 9 1 68030 11 1 689...   \n",
              "22   slide3                                                  0   \n",
              "33   slide4                                                  0   \n",
              "35   slide5  76 13348 16 76 15496 21 76 17645 24 76 19795 2...   \n",
              "\n",
              "                                           Lymphocyte Neutrophil  \\\n",
              "0   1 31277 7 1 31432 11 1 31588 13 1 31744 15 1 3...          0   \n",
              "11  57 1540 9 57 2488 13 57 3437 15 34 4278 6 57 4...          0   \n",
              "22  91 3209 7 91 3774 11 91 4340 12 91 4906 14 91 ...          0   \n",
              "33                                                  0          0   \n",
              "35                                                  0          0   \n",
              "\n",
              "                                           Macrophage  \n",
              "0   2 1850 16 2 2006 19 2 2161 22 2 2317 24 2 2472...  \n",
              "11                                                  0  \n",
              "22                                                  0  \n",
              "33  1 1524 6 1 1656 10 1 1787 15 1 1919 19 1 2051 ...  \n",
              "35                                                  0  "
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "submission_df = predict_maskrcnn_test_set(model, TEST_DIR, DEVICE,\n",
        "                                         score_thresh=0.5, mask_thresh=0.5,\n",
        "                                         resize_to=None)  # or resize_to=IMG_SIZE if you trained on resized input\n",
        "\n",
        "# (optional) sort by slide number like you did previously:\n",
        "submission_df['slide_num'] = submission_df['image_id'].str.extract(r'(\\d+)$').astype(int)\n",
        "submission_df = submission_df.sort_values('slide_num').drop(columns=['slide_num'])\n",
        "\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "print(\"Saved submission.csv â€” shape:\", submission_df.shape)\n",
        "submission_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Thiago model ends here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zg1MgP9agIOK"
      },
      "outputs": [],
      "source": [
        "def dice_loss(pred, target, smooth=1e-5):\n",
        "    pred = pred.contiguous()\n",
        "    target = target.contiguous()\n",
        "\n",
        "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
        "    loss = (1 - ((2. * intersection + smooth) /\n",
        "                 (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n",
        "\n",
        "    return loss.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "p0sbBENk5-xO"
      },
      "outputs": [],
      "source": [
        "def predict_test_set(model, test_dir, device, threshold=0.5):\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    test_tif_files = list(Path(test_dir).glob(\"*.tif\"))\n",
        "    submission_rows = []\n",
        "\n",
        "    print(f\"\\nPredicting on {len(test_tif_files)} test images...\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for tif_file in tqdm(test_tif_files):\n",
        "            image = cv2.imread(str(tif_file))\n",
        "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            original_shape = image_rgb.shape[:2]\n",
        "\n",
        "            image_resized = cv2.resize(image_rgb, (IMG_SIZE, IMG_SIZE))\n",
        "            image_norm = image_resized.astype(np.float32) / 255.0\n",
        "            image_tensor = torch.from_numpy(np.transpose(image_norm, (2, 0, 1))).unsqueeze(0).to(device)\n",
        "\n",
        "            output = model(image_tensor)\n",
        "            output = output.squeeze(0).cpu().numpy()\n",
        "\n",
        "            instance_masks = {}\n",
        "            for i, cell_type in enumerate(CLASSES):\n",
        "                mask = output[i]\n",
        "                mask = cv2.resize(mask, (original_shape[1], original_shape[0]))\n",
        "                binary_mask = (mask > threshold).astype(np.uint8)\n",
        "\n",
        "                labeled_mask, _ = ndimage.label(binary_mask)\n",
        "                instance_masks[cell_type] = labeled_mask.astype(np.uint16)\n",
        "\n",
        "            image_id = tif_file.stem\n",
        "            row = {'image_id': image_id}\n",
        "\n",
        "            for cell_type in CLASSES:\n",
        "                mask = instance_masks[cell_type]\n",
        "                row[cell_type] = rle_encode(mask) if np.max(mask) > 0 else \"\"\n",
        "\n",
        "                # If row[cell_type] is empty, add a 0\n",
        "                if not row[cell_type]:\n",
        "                    row[cell_type] = 0\n",
        "\n",
        "            submission_rows.append(row)\n",
        "\n",
        "    return pd.DataFrame(submission_rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QmrhghIV6Wa"
      },
      "source": [
        "## TA Model & Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvSVf_5_5xXA"
      },
      "outputs": [],
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=4):\n",
        "        super().__init__()\n",
        "\n",
        "        self.enc1 = DoubleConv(in_channels, 64)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.enc2 = DoubleConv(64, 128)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.enc3 = DoubleConv(128, 256)\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.bottleneck = DoubleConv(256, 512)\n",
        "\n",
        "        #these can produce checkerboard artifacts, therefore, I will replace them with nn.Upsample\n",
        "\n",
        "        \"\"\"\n",
        "        self.up3 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
        "        self.dec3 = DoubleConv(512, 256)\n",
        "\n",
        "        self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
        "        self.dec2 = DoubleConv(256, 128)\n",
        "\n",
        "        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
        "        self.dec1 = DoubleConv(128, 64)\n",
        "\n",
        "        self.out = nn.Conv2d(64, out_channels, 1)\"\"\"\n",
        "\n",
        "        self.up3 = Up(in_ch=512, skip_ch=256, out_ch=256)\n",
        "        self.up2 = Up(in_ch=256, skip_ch=128, out_ch=128)\n",
        "        self.up1 = Up(in_ch=128, skip_ch=64,  out_ch=64)\n",
        "\n",
        "        self.out = nn.Conv2d(64, out_channels, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        e1 = self.enc1(x)\n",
        "        e2 = self.enc2(self.pool1(e1))\n",
        "        e3 = self.enc3(self.pool2(e2))\n",
        "        b  = self.bottleneck(self.pool3(e3))\n",
        "\n",
        "        d3 = self.up3(b,  e3)\n",
        "        d2 = self.up2(d3, e2)\n",
        "        d1 = self.up1(d2, e1)\n",
        "\n",
        "        return torch.sigmoid(self.out(d1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lf3SHGnr5xUc"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, num_epochs, device):\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "    print(f\"\\nTraining on {device}\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "\n",
        "        for batch_idx, batch in enumerate(train_loader):\n",
        "            images = batch['image'].to(device)\n",
        "            masks = batch['mask'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = dice_loss(outputs, masks)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            if batch_idx % 5 == 0:\n",
        "                print(f\"Epoch [{epoch+1}/{num_epochs}] Batch [{batch_idx}/{len(train_loader)}] Loss: {loss.item():.4f}\")\n",
        "\n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] Avg Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njSlAzGz6Amm",
        "outputId": "bfb96417-b3a7-400f-9564-97a860222182"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating dataset...\n",
            "Train samples: 209\n",
            "\n",
            "Creating model...\n",
            "Parameters: 7,703,172\n",
            "\n",
            "Training...\n",
            "\n",
            "Training on cpu\n",
            "Epoch [1/3] Batch [0/53] Loss: 0.9472\n"
          ]
        }
      ],
      "source": [
        "print(\"Creating dataset...\")\n",
        "train_dataset = CellDataset(TRAIN_DIR, image_size=IMG_SIZE)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "print(f\"Train samples: {len(train_dataset)}\")\n",
        "\n",
        "print(\"\\nCreating model...\")\n",
        "model = UNet(in_channels=3, out_channels=4)\n",
        "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "print(\"\\nTraining...\")\n",
        "model = train_model(model, train_loader, EPOCHS, DEVICE)\n",
        "\n",
        "print(\"\\nGenerating predictions...\")\n",
        "submission_df = predict_test_set(model, TEST_DIR, DEVICE)\n",
        "\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "print(f\"\\nâœ… Submission saved: submission.csv\")\n",
        "print(f\"Shape: {submission_df.shape}\")\n",
        "print(\"\\nSample rows:\")\n",
        "print(submission_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "C3inzVOb7Dwy",
        "outputId": "18803261-c1f5-46d0-b262-9e7a0431b9c2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"submission_display\",\n  \"rows\": 40,\n  \"fields\": [\n    {\n      \"column\": \"image_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 40,\n        \"samples\": [\n          \"slide17\",\n          \"slide8\",\n          \"slide14\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Epithelial\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 40,\n        \"samples\": [\n          \"1 2 2 5 39 19 5 62 2 105 224 6 105 234 2...\",\n          \"24 1652 1 6 1710 10 24 1837 1 6 1892 15 ...\",\n          \"40 10910 3 40 11215 6 40 11521 7 40 1182...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lymphocyte\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 40,\n        \"samples\": [\n          \"3 40 17 61 225 4 61 236 17 2 255 2 3 292...\",\n          \"4 1711 9 4 1893 14 4 2077 16 4 2261 17 4...\",\n          \"19 10910 2 19 11215 6 19 11521 7 19 1182...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Neutrophil\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 40,\n        \"samples\": [\n          \"1 38 21 1 62 3 17 224 29 1 255 3 1 289 3...\",\n          \"4 1526 10 4 1708 15 4 1891 18 4 2075 20 ...\",\n          \"12 10910 3 12 11215 6 12 11521 7 12 1182...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Macrophage\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 40,\n        \"samples\": [\n          \"1 1 6 1 35 36 58 193 7 94 223 31 1 254 6...\",\n          \"6 1524 13 31 1652 2 6 1707 17 31 1836 3 ...\",\n          \"79 10338 1 79 10643 2 59 10910 3 79 1094...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "submission_display"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-4a2f8180-da60-40f0-96e2-34abca933bf8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>Epithelial</th>\n",
              "      <th>Lymphocyte</th>\n",
              "      <th>Neutrophil</th>\n",
              "      <th>Macrophage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>slide15</td>\n",
              "      <td>32 962 1 32 1087 1 19 1686 2 34 1720 2 1...</td>\n",
              "      <td>8 3442 3 8 3566 5 6 3677 2 8 3689 7 6 38...</td>\n",
              "      <td>5 3442 3 4 3550 6 5 3566 5 4 3674 8 5 36...</td>\n",
              "      <td>15 961 3 15 1087 2 11 1426 1 11 1551 2 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>slide2</td>\n",
              "      <td>9 25 10 13 64 9 26 91 15 34 118 20 35 15...</td>\n",
              "      <td>12 27 7 26 67 3 34 95 10 46 121 2 46 128...</td>\n",
              "      <td>2 25 10 1 64 11 1 90 18 1 117 23 1 152 1...</td>\n",
              "      <td>2 17 20 1 51 127 1 187 34 1 231 250 1 52...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>slide3</td>\n",
              "      <td>142 325 18 155 364 11 142 892 18 155 931...</td>\n",
              "      <td>133 325 18 148 365 8 133 892 18 148 931 ...</td>\n",
              "      <td>29 325 19 34 363 15 40 499 5 29 892 19 3...</td>\n",
              "      <td>24 146 14 32 291 11 32 324 24 33 357 24 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>slide13</td>\n",
              "      <td>35 279 11 35 293 4 35 449 21 35 619 14 3...</td>\n",
              "      <td>20 1878 3 20 2047 6 20 2217 7 20 2386 9 ...</td>\n",
              "      <td>16 1707 3 16 1876 6 16 2046 7 16 2215 9 ...</td>\n",
              "      <td>22 107 20 22 277 22 22 448 27 22 619 28 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>slide16</td>\n",
              "      <td>17 36 1 17 58 12 17 76 13 49 96 29 49 12...</td>\n",
              "      <td>24 61 8 50 78 10 58 97 28 77 130 19 42 1...</td>\n",
              "      <td>1 18 5 1 26 16 1 57 35 1 94 57 1 154 8 1...</td>\n",
              "      <td>1 1 301 1 310 394 1 710 397 1 1110 11610...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>slide28</td>\n",
              "      <td>6 63 6 6 282 12 6 310 14 6 502 16 6 524 ...</td>\n",
              "      <td>5 282 11 5 503 16 5 524 11 5 724 32 5 94...</td>\n",
              "      <td>4 62 12 4 86 6 4 281 34 4 501 35 4 723 3...</td>\n",
              "      <td>6 58 47 6 279 47 6 501 46 6 722 46 6 944...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>slide22</td>\n",
              "      <td>14 21 12 20 65 34 38 152 33 53 223 19 53...</td>\n",
              "      <td>14 22 10 22 66 32 48 153 18 65 224 17 65...</td>\n",
              "      <td>3 20 15 3 64 36 3 151 36 3 197 2 3 223 1...</td>\n",
              "      <td>2 18 20 2 52 81 2 144 70 2 220 25 2 252 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>slide4</td>\n",
              "      <td>13 1025 1 13 1157 5 13 1288 8 13 1418 11...</td>\n",
              "      <td>1 2460 12 1 2591 17 1 2724 19 1 2857 21 ...</td>\n",
              "      <td>1 2059 1 1 2069 1 1 2192 14 1 2322 18 1 ...</td>\n",
              "      <td>19 1023 5 19 1155 8 19 1287 11 19 1416 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>slide39</td>\n",
              "      <td>1 1 4 34 66 2 1 223 5 15 239 2 26 272 3 ...</td>\n",
              "      <td>1 2 2 1 223 4 1 445 4 1 667 4 1 889 3 1 ...</td>\n",
              "      <td>1 2 3 1 223 4 1 445 4 1 667 4 1 889 3 1 ...</td>\n",
              "      <td>1 1 6 8 13 9 3 49 6 3 58 2 15 63 13 49 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>slide27</td>\n",
              "      <td>53 19103 4 53 19845 5 53 20587 7 53 2133...</td>\n",
              "      <td>21 44283 6 21 45024 10 21 45765 12 21 46...</td>\n",
              "      <td>20 44284 4 20 45024 9 20 45766 11 20 465...</td>\n",
              "      <td>58 17618 3 58 18359 6 58 19101 7 58 1984...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>slide1</td>\n",
              "      <td>1 179 2 1 334 4 1 490 5 1 646 5 1 803 4 ...</td>\n",
              "      <td>10 13142 1 10 13299 2 10 13456 2 10 1361...</td>\n",
              "      <td>9 13142 1 9 13299 2 9 13456 2 9 13612 4 ...</td>\n",
              "      <td>1 19 6 1 175 7 1 332 7 1 489 6 1 645 7 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>slide24</td>\n",
              "      <td>3 22 7 3 46 63 3 131 9 3 172 14 3 219 34...</td>\n",
              "      <td>4 52 32 4 87 20 4 221 29 4 287 55 53 356...</td>\n",
              "      <td>1 21 13 1 41 71 1 127 30 1 171 17 1 218 ...</td>\n",
              "      <td>1 2 197 1 210 572 1 783 197 1 991 771 1 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>slide5</td>\n",
              "      <td>43 144 5 254 1155 22 292 1359 5 43 2294 ...</td>\n",
              "      <td>11 13045 1 11 15195 2 11 17345 2 71 1841...</td>\n",
              "      <td>45 18413 1 45 20557 9 45 22705 13 45 248...</td>\n",
              "      <td>23 74 44 28 128 32 29 193 34 54 311 46 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>slide33</td>\n",
              "      <td>1 14 4 1 30 24 1 66 4 1 99 15 1 118 15 4...</td>\n",
              "      <td>1 31 22 1 99 14 1 120 9 1 191 22 1 259 1...</td>\n",
              "      <td>1 7 14 1 30 24 1 61 12 1 99 33 1 157 3 1...</td>\n",
              "      <td>1 1 55 1 59 157 1 219 157 1 379 157 1 53...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>slide30</td>\n",
              "      <td>6 27 12 23 81 2 6 263 5 6 279 13 23 332 ...</td>\n",
              "      <td>2 28 10 2 279 13 2 531 14 2 783 15 2 103...</td>\n",
              "      <td>1 27 13 1 271 4 1 278 16 1 523 5 1 530 1...</td>\n",
              "      <td>1 1 4 1 9 15 1 25 31 8 61 3 8 71 13 13 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>slide14</td>\n",
              "      <td>40 10910 3 40 11215 6 40 11521 7 40 1182...</td>\n",
              "      <td>19 10910 2 19 11215 6 19 11521 7 19 1182...</td>\n",
              "      <td>12 10910 3 12 11215 6 12 11521 7 12 1182...</td>\n",
              "      <td>79 10338 1 79 10643 2 59 10910 3 79 1094...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>slide8</td>\n",
              "      <td>24 1652 1 6 1710 10 24 1837 1 6 1892 15 ...</td>\n",
              "      <td>4 1711 9 4 1893 14 4 2077 16 4 2261 17 4...</td>\n",
              "      <td>4 1526 10 4 1708 15 4 1891 18 4 2075 20 ...</td>\n",
              "      <td>6 1524 13 31 1652 2 6 1707 17 31 1836 3 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>slide7</td>\n",
              "      <td>4 5656 3 4 5892 5 4 6127 8 4 6363 10 4 6...</td>\n",
              "      <td>4 5656 3 4 5892 5 4 6128 7 4 6364 9 4 66...</td>\n",
              "      <td>4 5416 5 4 5650 10 4 5887 11 4 6123 13 4...</td>\n",
              "      <td>4 720 2 4 957 2 4 1194 2 3 3326 1 3 3562...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>slide20</td>\n",
              "      <td>9 51 3 26 72 2 34 81 2 40 136 4 9 192 2 ...</td>\n",
              "      <td>22 136 4 22 275 4 3 294 2 22 415 3 3 431...</td>\n",
              "      <td>16 136 4 2 154 3 16 275 4 2 291 7 16 415...</td>\n",
              "      <td>2 15 1 2 49 6 11 71 3 14 80 4 20 135 5 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>slide17</td>\n",
              "      <td>1 2 2 5 39 19 5 62 2 105 224 6 105 234 2...</td>\n",
              "      <td>3 40 17 61 225 4 61 236 17 2 255 2 3 292...</td>\n",
              "      <td>1 38 21 1 62 3 17 224 29 1 255 3 1 289 3...</td>\n",
              "      <td>1 1 6 1 35 36 58 193 7 94 223 31 1 254 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>slide35</td>\n",
              "      <td>162 296 2 162 620 3 162 945 4 173 963 3 ...</td>\n",
              "      <td>15 3952 5 15 4276 7 15 4600 10 15 4925 1...</td>\n",
              "      <td>5 714 8 5 1038 11 5 1363 11 5 1688 10 5 ...</td>\n",
              "      <td>1 1 6 2 13 9 2 32 4 2 62 16 31 104 3 62 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>slide38</td>\n",
              "      <td>46 143 21 62 227 39 92 351 43 153 645 36...</td>\n",
              "      <td>65 235 27 99 355 26 172 668 6 241 864 4 ...</td>\n",
              "      <td>1 73 7 1 143 23 6 230 32 1 352 45 1 644 ...</td>\n",
              "      <td>1 1 111 1 124 803 1 956 325 1 1330 9 1 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>slide29</td>\n",
              "      <td>73 591 10 50 617 8 50 640 14 50 667 81 8...</td>\n",
              "      <td>75 620 3 79 645 5 70 686 42 70 732 14 95...</td>\n",
              "      <td>9 592 10 9 617 9 9 639 18 9 665 84 9 756...</td>\n",
              "      <td>65 475 15 65 501 8 62 579 414 62 1001 11...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>slide6</td>\n",
              "      <td>24 3123 8 24 3321 15 24 3520 21 24 3721 ...</td>\n",
              "      <td>8 3327 5 8 3527 8 8 3728 8 8 3929 9 8 41...</td>\n",
              "      <td>7 3328 2 7 3528 6 7 3728 8 7 3929 9 7 41...</td>\n",
              "      <td>56 1750 1 41 2722 1 41 2922 10 41 3122 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>slide31</td>\n",
              "      <td>1 5 3 20 35 1 19 44 3 33 119 8 1 152 7 1...</td>\n",
              "      <td>12 121 2 12 270 4 2 1659 5 2 1809 6 2 19...</td>\n",
              "      <td>11 120 3 11 270 5 11 422 1 2 1512 1 2 16...</td>\n",
              "      <td>1 1 9 8 23 5 11 34 3 3 42 6 15 118 23 15...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>slide21</td>\n",
              "      <td>11 118 4 12 225 3 11 240 6 12 348 3 11 3...</td>\n",
              "      <td>6 118 4 6 240 6 6 364 5 6 487 5 6 610 5 ...</td>\n",
              "      <td>5 117 6 5 239 8 5 362 8 5 485 8 5 608 8 ...</td>\n",
              "      <td>7 102 3 6 115 9 7 225 3 6 238 9 7 347 4 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>slide18</td>\n",
              "      <td>98 163 4 39 246 6 70 283 4 98 342 11 39 ...</td>\n",
              "      <td>6 164 1 6 343 2 1 1287 4 7 1420 2 1 1463...</td>\n",
              "      <td>5 164 1 5 343 2 1 1282 14 6 1420 2 6 142...</td>\n",
              "      <td>34 67 6 66 104 3 79 163 11 26 238 1 34 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>slide34</td>\n",
              "      <td>23 42 22 23 83 16 23 108 2 23 122 5 23 1...</td>\n",
              "      <td>21 43 3 21 49 7 21 61 2 26 88 4 26 137 1...</td>\n",
              "      <td>1 41 25 1 83 17 1 107 22 1 132 25 10 203...</td>\n",
              "      <td>1 1 15 1 22 11 1 34 132 2 192 53 1 349 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>slide32</td>\n",
              "      <td>50 510 14 184 1332 12 214 1518 42 269 18...</td>\n",
              "      <td>47 13185 3 47 15156 9 47 17129 12 47 191...</td>\n",
              "      <td>24 9232 8 24 11204 15 24 13176 20 24 151...</td>\n",
              "      <td>22 126 34 27 241 32 30 397 42 3 498 85 5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>slide19</td>\n",
              "      <td>2 3 1 2 177 3 2 351 4 2 526 5 30 905 1 3...</td>\n",
              "      <td>2 177 2 2 350 6 2 525 7 2 702 3 6 731 1 ...</td>\n",
              "      <td>3 176 11 1 207 2 3 350 11 1 366 11 1 379...</td>\n",
              "      <td>1 1 13 2 17 20 1 175 13 2 191 20 1 349 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>slide11</td>\n",
              "      <td>178 3760 2 86 4106 3 178 4392 5 86 4738 ...</td>\n",
              "      <td>72 4106 3 133 4395 1 72 4738 5 133 5026 ...</td>\n",
              "      <td>44 2841 2 44 3471 7 44 4104 8 81 4393 2 ...</td>\n",
              "      <td>37 176 4 64 307 5 125 571 23 37 809 4 64...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>slide9</td>\n",
              "      <td>8 43 5 103 492 5 103 506 10 151 738 11 1...</td>\n",
              "      <td>99 3528 2 153 3757 4 6 4062 4 99 4511 5 ...</td>\n",
              "      <td>74 492 5 74 507 8 74 1497 5 74 1512 8 74...</td>\n",
              "      <td>8 16 3 8 40 13 20 70 13 22 96 4 48 286 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>slide23</td>\n",
              "      <td>35 69 11 50 107 23 79 149 5 79 155 16 11...</td>\n",
              "      <td>58 110 18 139 240 4 139 252 12 293 501 7...</td>\n",
              "      <td>1 55 1 1 67 20 1 90 4 1 106 25 1 148 24 ...</td>\n",
              "      <td>1 6 213 1 225 76 1 330 50 1 387 75 1 471...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>slide25</td>\n",
              "      <td>31 76 2 56 171 28 132 456 12 150 514 34 ...</td>\n",
              "      <td>45 5455 1 177 5923 4 45 6751 24 177 7235...</td>\n",
              "      <td>24 178 22 24 1493 22 24 2807 27 24 4118 ...</td>\n",
              "      <td>22 67 19 38 155 84 38 244 6 59 352 29 69...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>slide10</td>\n",
              "      <td>1 19 7 138 209 7 194 343 13 260 394 8 31...</td>\n",
              "      <td>144 211 4 238 344 10 341 507 6 374 557 7...</td>\n",
              "      <td>1 18 9 2 210 5 29 343 13 45 394 9 54 503...</td>\n",
              "      <td>1 10 21 2 177 16 2 203 14 19 257 12 2 34...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>slide36</td>\n",
              "      <td>33 155 18 33 192 16 33 243 8 33 297 14 1...</td>\n",
              "      <td>78 298 11 78 406 3 78 728 11 78 836 3 78...</td>\n",
              "      <td>1 110 5 1 152 26 1 192 18 1 219 6 1 242 ...</td>\n",
              "      <td>1 1 429 1 431 429 1 861 429 1 1291 429 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>slide26</td>\n",
              "      <td>44 79 17 82 194 15 94 255 11 114 281 13 ...</td>\n",
              "      <td>44 79 16 89 196 1 89 204 4 104 259 3 126...</td>\n",
              "      <td>1 40 7 1 78 19 1 137 12 1 193 17 1 252 1...</td>\n",
              "      <td>1 3 1 1 11 13 1 34 19 1 74 43 1 134 36 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>slide37</td>\n",
              "      <td>11 11 2 13 20 6 13 31 5 22 48 5 1 130 2 ...</td>\n",
              "      <td>4 21 5 8 32 3 4 148 6 8 159 5 11 176 6 4...</td>\n",
              "      <td>1 17 20 1 47 7 1 142 24 3 168 2 1 173 11...</td>\n",
              "      <td>1 1 5 1 10 33 1 44 11 1 60 11 1 72 14 1 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>slide40</td>\n",
              "      <td>43 99 3 55 106 2 61 119 2 59 151 5 79 23...</td>\n",
              "      <td>115 235 5 40 399 3 51 406 2 55 418 3 78 ...</td>\n",
              "      <td>1 4 2 3 89 8 3 98 13 3 114 3 3 119 3 3 2...</td>\n",
              "      <td>1 1 11 1 21 3 1 64 70 1 146 16 1 194 1 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>slide12</td>\n",
              "      <td>3 3722 2 23 3914 1 1 3917 4 3 3927 2 23 ...</td>\n",
              "      <td>13 4118 3 13 4323 4 13 4527 6 13 4732 7 ...</td>\n",
              "      <td>12 3912 3 11 4085 4 12 4117 4 11 4289 7 ...</td>\n",
              "      <td>3 3105 1 3 3311 2 3 3516 3 23 3707 2 3 3...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a2f8180-da60-40f0-96e2-34abca933bf8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4a2f8180-da60-40f0-96e2-34abca933bf8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4a2f8180-da60-40f0-96e2-34abca933bf8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-799afbb7-c86b-4b34-9483-e40a84dbecf4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-799afbb7-c86b-4b34-9483-e40a84dbecf4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-799afbb7-c86b-4b34-9483-e40a84dbecf4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_70a7b179-6ee2-4c9c-82d2-caed982ea868\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('submission_display')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_70a7b179-6ee2-4c9c-82d2-caed982ea868 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('submission_display');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   image_id                                   Epithelial  \\\n",
              "0   slide15  32 962 1 32 1087 1 19 1686 2 34 1720 2 1...   \n",
              "1    slide2  9 25 10 13 64 9 26 91 15 34 118 20 35 15...   \n",
              "2    slide3  142 325 18 155 364 11 142 892 18 155 931...   \n",
              "3   slide13  35 279 11 35 293 4 35 449 21 35 619 14 3...   \n",
              "4   slide16  17 36 1 17 58 12 17 76 13 49 96 29 49 12...   \n",
              "5   slide28  6 63 6 6 282 12 6 310 14 6 502 16 6 524 ...   \n",
              "6   slide22  14 21 12 20 65 34 38 152 33 53 223 19 53...   \n",
              "7    slide4  13 1025 1 13 1157 5 13 1288 8 13 1418 11...   \n",
              "8   slide39  1 1 4 34 66 2 1 223 5 15 239 2 26 272 3 ...   \n",
              "9   slide27  53 19103 4 53 19845 5 53 20587 7 53 2133...   \n",
              "10   slide1  1 179 2 1 334 4 1 490 5 1 646 5 1 803 4 ...   \n",
              "11  slide24  3 22 7 3 46 63 3 131 9 3 172 14 3 219 34...   \n",
              "12   slide5  43 144 5 254 1155 22 292 1359 5 43 2294 ...   \n",
              "13  slide33  1 14 4 1 30 24 1 66 4 1 99 15 1 118 15 4...   \n",
              "14  slide30  6 27 12 23 81 2 6 263 5 6 279 13 23 332 ...   \n",
              "15  slide14  40 10910 3 40 11215 6 40 11521 7 40 1182...   \n",
              "16   slide8  24 1652 1 6 1710 10 24 1837 1 6 1892 15 ...   \n",
              "17   slide7  4 5656 3 4 5892 5 4 6127 8 4 6363 10 4 6...   \n",
              "18  slide20  9 51 3 26 72 2 34 81 2 40 136 4 9 192 2 ...   \n",
              "19  slide17  1 2 2 5 39 19 5 62 2 105 224 6 105 234 2...   \n",
              "20  slide35  162 296 2 162 620 3 162 945 4 173 963 3 ...   \n",
              "21  slide38  46 143 21 62 227 39 92 351 43 153 645 36...   \n",
              "22  slide29  73 591 10 50 617 8 50 640 14 50 667 81 8...   \n",
              "23   slide6  24 3123 8 24 3321 15 24 3520 21 24 3721 ...   \n",
              "24  slide31  1 5 3 20 35 1 19 44 3 33 119 8 1 152 7 1...   \n",
              "25  slide21  11 118 4 12 225 3 11 240 6 12 348 3 11 3...   \n",
              "26  slide18  98 163 4 39 246 6 70 283 4 98 342 11 39 ...   \n",
              "27  slide34  23 42 22 23 83 16 23 108 2 23 122 5 23 1...   \n",
              "28  slide32  50 510 14 184 1332 12 214 1518 42 269 18...   \n",
              "29  slide19  2 3 1 2 177 3 2 351 4 2 526 5 30 905 1 3...   \n",
              "30  slide11  178 3760 2 86 4106 3 178 4392 5 86 4738 ...   \n",
              "31   slide9  8 43 5 103 492 5 103 506 10 151 738 11 1...   \n",
              "32  slide23  35 69 11 50 107 23 79 149 5 79 155 16 11...   \n",
              "33  slide25  31 76 2 56 171 28 132 456 12 150 514 34 ...   \n",
              "34  slide10  1 19 7 138 209 7 194 343 13 260 394 8 31...   \n",
              "35  slide36  33 155 18 33 192 16 33 243 8 33 297 14 1...   \n",
              "36  slide26  44 79 17 82 194 15 94 255 11 114 281 13 ...   \n",
              "37  slide37  11 11 2 13 20 6 13 31 5 22 48 5 1 130 2 ...   \n",
              "38  slide40  43 99 3 55 106 2 61 119 2 59 151 5 79 23...   \n",
              "39  slide12  3 3722 2 23 3914 1 1 3917 4 3 3927 2 23 ...   \n",
              "\n",
              "                                     Lymphocyte  \\\n",
              "0   8 3442 3 8 3566 5 6 3677 2 8 3689 7 6 38...   \n",
              "1   12 27 7 26 67 3 34 95 10 46 121 2 46 128...   \n",
              "2   133 325 18 148 365 8 133 892 18 148 931 ...   \n",
              "3   20 1878 3 20 2047 6 20 2217 7 20 2386 9 ...   \n",
              "4   24 61 8 50 78 10 58 97 28 77 130 19 42 1...   \n",
              "5   5 282 11 5 503 16 5 524 11 5 724 32 5 94...   \n",
              "6   14 22 10 22 66 32 48 153 18 65 224 17 65...   \n",
              "7   1 2460 12 1 2591 17 1 2724 19 1 2857 21 ...   \n",
              "8   1 2 2 1 223 4 1 445 4 1 667 4 1 889 3 1 ...   \n",
              "9   21 44283 6 21 45024 10 21 45765 12 21 46...   \n",
              "10  10 13142 1 10 13299 2 10 13456 2 10 1361...   \n",
              "11  4 52 32 4 87 20 4 221 29 4 287 55 53 356...   \n",
              "12  11 13045 1 11 15195 2 11 17345 2 71 1841...   \n",
              "13  1 31 22 1 99 14 1 120 9 1 191 22 1 259 1...   \n",
              "14  2 28 10 2 279 13 2 531 14 2 783 15 2 103...   \n",
              "15  19 10910 2 19 11215 6 19 11521 7 19 1182...   \n",
              "16  4 1711 9 4 1893 14 4 2077 16 4 2261 17 4...   \n",
              "17  4 5656 3 4 5892 5 4 6128 7 4 6364 9 4 66...   \n",
              "18  22 136 4 22 275 4 3 294 2 22 415 3 3 431...   \n",
              "19  3 40 17 61 225 4 61 236 17 2 255 2 3 292...   \n",
              "20  15 3952 5 15 4276 7 15 4600 10 15 4925 1...   \n",
              "21  65 235 27 99 355 26 172 668 6 241 864 4 ...   \n",
              "22  75 620 3 79 645 5 70 686 42 70 732 14 95...   \n",
              "23  8 3327 5 8 3527 8 8 3728 8 8 3929 9 8 41...   \n",
              "24  12 121 2 12 270 4 2 1659 5 2 1809 6 2 19...   \n",
              "25  6 118 4 6 240 6 6 364 5 6 487 5 6 610 5 ...   \n",
              "26  6 164 1 6 343 2 1 1287 4 7 1420 2 1 1463...   \n",
              "27  21 43 3 21 49 7 21 61 2 26 88 4 26 137 1...   \n",
              "28  47 13185 3 47 15156 9 47 17129 12 47 191...   \n",
              "29  2 177 2 2 350 6 2 525 7 2 702 3 6 731 1 ...   \n",
              "30  72 4106 3 133 4395 1 72 4738 5 133 5026 ...   \n",
              "31  99 3528 2 153 3757 4 6 4062 4 99 4511 5 ...   \n",
              "32  58 110 18 139 240 4 139 252 12 293 501 7...   \n",
              "33  45 5455 1 177 5923 4 45 6751 24 177 7235...   \n",
              "34  144 211 4 238 344 10 341 507 6 374 557 7...   \n",
              "35  78 298 11 78 406 3 78 728 11 78 836 3 78...   \n",
              "36  44 79 16 89 196 1 89 204 4 104 259 3 126...   \n",
              "37  4 21 5 8 32 3 4 148 6 8 159 5 11 176 6 4...   \n",
              "38  115 235 5 40 399 3 51 406 2 55 418 3 78 ...   \n",
              "39  13 4118 3 13 4323 4 13 4527 6 13 4732 7 ...   \n",
              "\n",
              "                                     Neutrophil  \\\n",
              "0   5 3442 3 4 3550 6 5 3566 5 4 3674 8 5 36...   \n",
              "1   2 25 10 1 64 11 1 90 18 1 117 23 1 152 1...   \n",
              "2   29 325 19 34 363 15 40 499 5 29 892 19 3...   \n",
              "3   16 1707 3 16 1876 6 16 2046 7 16 2215 9 ...   \n",
              "4   1 18 5 1 26 16 1 57 35 1 94 57 1 154 8 1...   \n",
              "5   4 62 12 4 86 6 4 281 34 4 501 35 4 723 3...   \n",
              "6   3 20 15 3 64 36 3 151 36 3 197 2 3 223 1...   \n",
              "7   1 2059 1 1 2069 1 1 2192 14 1 2322 18 1 ...   \n",
              "8   1 2 3 1 223 4 1 445 4 1 667 4 1 889 3 1 ...   \n",
              "9   20 44284 4 20 45024 9 20 45766 11 20 465...   \n",
              "10  9 13142 1 9 13299 2 9 13456 2 9 13612 4 ...   \n",
              "11  1 21 13 1 41 71 1 127 30 1 171 17 1 218 ...   \n",
              "12  45 18413 1 45 20557 9 45 22705 13 45 248...   \n",
              "13  1 7 14 1 30 24 1 61 12 1 99 33 1 157 3 1...   \n",
              "14  1 27 13 1 271 4 1 278 16 1 523 5 1 530 1...   \n",
              "15  12 10910 3 12 11215 6 12 11521 7 12 1182...   \n",
              "16  4 1526 10 4 1708 15 4 1891 18 4 2075 20 ...   \n",
              "17  4 5416 5 4 5650 10 4 5887 11 4 6123 13 4...   \n",
              "18  16 136 4 2 154 3 16 275 4 2 291 7 16 415...   \n",
              "19  1 38 21 1 62 3 17 224 29 1 255 3 1 289 3...   \n",
              "20  5 714 8 5 1038 11 5 1363 11 5 1688 10 5 ...   \n",
              "21  1 73 7 1 143 23 6 230 32 1 352 45 1 644 ...   \n",
              "22  9 592 10 9 617 9 9 639 18 9 665 84 9 756...   \n",
              "23  7 3328 2 7 3528 6 7 3728 8 7 3929 9 7 41...   \n",
              "24  11 120 3 11 270 5 11 422 1 2 1512 1 2 16...   \n",
              "25  5 117 6 5 239 8 5 362 8 5 485 8 5 608 8 ...   \n",
              "26  5 164 1 5 343 2 1 1282 14 6 1420 2 6 142...   \n",
              "27  1 41 25 1 83 17 1 107 22 1 132 25 10 203...   \n",
              "28  24 9232 8 24 11204 15 24 13176 20 24 151...   \n",
              "29  3 176 11 1 207 2 3 350 11 1 366 11 1 379...   \n",
              "30  44 2841 2 44 3471 7 44 4104 8 81 4393 2 ...   \n",
              "31  74 492 5 74 507 8 74 1497 5 74 1512 8 74...   \n",
              "32  1 55 1 1 67 20 1 90 4 1 106 25 1 148 24 ...   \n",
              "33  24 178 22 24 1493 22 24 2807 27 24 4118 ...   \n",
              "34  1 18 9 2 210 5 29 343 13 45 394 9 54 503...   \n",
              "35  1 110 5 1 152 26 1 192 18 1 219 6 1 242 ...   \n",
              "36  1 40 7 1 78 19 1 137 12 1 193 17 1 252 1...   \n",
              "37  1 17 20 1 47 7 1 142 24 3 168 2 1 173 11...   \n",
              "38  1 4 2 3 89 8 3 98 13 3 114 3 3 119 3 3 2...   \n",
              "39  12 3912 3 11 4085 4 12 4117 4 11 4289 7 ...   \n",
              "\n",
              "                                     Macrophage  \n",
              "0   15 961 3 15 1087 2 11 1426 1 11 1551 2 3...  \n",
              "1   2 17 20 1 51 127 1 187 34 1 231 250 1 52...  \n",
              "2   24 146 14 32 291 11 32 324 24 33 357 24 ...  \n",
              "3   22 107 20 22 277 22 22 448 27 22 619 28 ...  \n",
              "4   1 1 301 1 310 394 1 710 397 1 1110 11610...  \n",
              "5   6 58 47 6 279 47 6 501 46 6 722 46 6 944...  \n",
              "6   2 18 20 2 52 81 2 144 70 2 220 25 2 252 ...  \n",
              "7   19 1023 5 19 1155 8 19 1287 11 19 1416 1...  \n",
              "8   1 1 6 8 13 9 3 49 6 3 58 2 15 63 13 49 1...  \n",
              "9   58 17618 3 58 18359 6 58 19101 7 58 1984...  \n",
              "10  1 19 6 1 175 7 1 332 7 1 489 6 1 645 7 1...  \n",
              "11  1 2 197 1 210 572 1 783 197 1 991 771 1 ...  \n",
              "12  23 74 44 28 128 32 29 193 34 54 311 46 2...  \n",
              "13  1 1 55 1 59 157 1 219 157 1 379 157 1 53...  \n",
              "14  1 1 4 1 9 15 1 25 31 8 61 3 8 71 13 13 1...  \n",
              "15  79 10338 1 79 10643 2 59 10910 3 79 1094...  \n",
              "16  6 1524 13 31 1652 2 6 1707 17 31 1836 3 ...  \n",
              "17  4 720 2 4 957 2 4 1194 2 3 3326 1 3 3562...  \n",
              "18  2 15 1 2 49 6 11 71 3 14 80 4 20 135 5 2...  \n",
              "19  1 1 6 1 35 36 58 193 7 94 223 31 1 254 6...  \n",
              "20  1 1 6 2 13 9 2 32 4 2 62 16 31 104 3 62 ...  \n",
              "21  1 1 111 1 124 803 1 956 325 1 1330 9 1 1...  \n",
              "22  65 475 15 65 501 8 62 579 414 62 1001 11...  \n",
              "23  56 1750 1 41 2722 1 41 2922 10 41 3122 1...  \n",
              "24  1 1 9 8 23 5 11 34 3 3 42 6 15 118 23 15...  \n",
              "25  7 102 3 6 115 9 7 225 3 6 238 9 7 347 4 ...  \n",
              "26  34 67 6 66 104 3 79 163 11 26 238 1 34 2...  \n",
              "27  1 1 15 1 22 11 1 34 132 2 192 53 1 349 1...  \n",
              "28  22 126 34 27 241 32 30 397 42 3 498 85 5...  \n",
              "29  1 1 13 2 17 20 1 175 13 2 191 20 1 349 1...  \n",
              "30  37 176 4 64 307 5 125 571 23 37 809 4 64...  \n",
              "31  8 16 3 8 40 13 20 70 13 22 96 4 48 286 1...  \n",
              "32  1 6 213 1 225 76 1 330 50 1 387 75 1 471...  \n",
              "33  22 67 19 38 155 84 38 244 6 59 352 29 69...  \n",
              "34  1 10 21 2 177 16 2 203 14 19 257 12 2 34...  \n",
              "35  1 1 429 1 431 429 1 861 429 1 1291 429 1...  \n",
              "36  1 3 1 1 11 13 1 34 19 1 74 43 1 134 36 1...  \n",
              "37  1 1 5 1 10 33 1 44 11 1 60 11 1 72 14 1 ...  \n",
              "38  1 1 11 1 21 3 1 64 70 1 146 16 1 194 1 1...  \n",
              "39  3 3105 1 3 3311 2 3 3516 3 23 3707 2 3 3...  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "submission = pd.read_csv('/content/submission.csv')\n",
        "\n",
        "# Truncate RLE columns for display\n",
        "submission_display = submission.copy()\n",
        "for col in ['Epithelial', 'Lymphocyte', 'Neutrophil', 'Macrophage']:\n",
        "    submission_display[col] = submission_display[col].astype(str).str[:40] + '...'\n",
        "\n",
        "submission_display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p34NAU8aPpaI"
      },
      "source": [
        "## Single Image Visualization\n",
        "The above classes do not create a simple visualization tool for a single image so we can create one as a sanity check and to view flaws in model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97bbf061"
      },
      "outputs": [],
      "source": [
        "def analyze_and_visualize_masks(image_path, model, ground_truth_df, image_size=IMG_SIZE, device=DEVICE, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Loads an image, runs inference with the model, decodes ground truth masks,\n",
        "    and visualizes both predicted and ground truth masks.\n",
        "\n",
        "    Args:\n",
        "        image_path (Path): Path to the image file.\n",
        "        model (torch.nn.Module): Trained segmentation model.\n",
        "        ground_truth_df (pd.DataFrame): DataFrame containing ground truth RLEs, indexed by image_id.\n",
        "        image_size (int): The size to resize the image for model input.\n",
        "        device (str): The device to run inference on ('cuda' or 'cpu').\n",
        "        threshold (float): Threshold for converting predicted probabilities to binary masks.\n",
        "    \"\"\"\n",
        "    # --- Load and preprocess image for inference ---\n",
        "    image = cv2.imread(str(image_path))\n",
        "    if image is None:\n",
        "        print(f\"Error loading image: {image_path}. Skipping analysis.\")\n",
        "        return\n",
        "\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    original_shape = image_rgb.shape[:2]\n",
        "\n",
        "    image_resized = cv2.resize(image_rgb, (image_size, image_size))\n",
        "    image_norm = image_resized.astype(np.float32) / 255.0\n",
        "    image_tensor = torch.from_numpy(np.transpose(image_norm, (2, 0, 1))).unsqueeze(0).to(device)\n",
        "\n",
        "    # --- Run Inference ---\n",
        "    model.eval()\n",
        "    predicted_masks = None\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image_tensor)\n",
        "        predicted_masks = outputs.squeeze(0).cpu().numpy()\n",
        "\n",
        "    if predicted_masks is None:\n",
        "        print(\"Inference failed. Could not generate predicted masks.\")\n",
        "        return\n",
        "\n",
        "    # --- Get and decode Ground Truth ---\n",
        "    image_id = image_path.stem\n",
        "    if image_id not in ground_truth_df.index:\n",
        "        print(f\"Ground truth not found for image: {image_id}.\")\n",
        "        masks_ground_truth = None\n",
        "    else:\n",
        "        slide_ground_truth = ground_truth_df.loc[image_id].to_dict()\n",
        "        masks_ground_truth = {}\n",
        "        for cell_type in CLASSES:\n",
        "            rle = slide_ground_truth.get(cell_type, \"\") # Use .get with default empty string\n",
        "            mask = rle_decode(rle, original_shape)\n",
        "            masks_ground_truth[cell_type] = mask\n",
        "\n",
        "    # --- Visualize Results ---\n",
        "    num_cols = len(CLASSES) + 1\n",
        "    fig, axs = plt.subplots(2, num_cols, figsize=(5 * num_cols, 10))\n",
        "\n",
        "    # Display original image\n",
        "    axs[0][0].imshow(image_rgb)\n",
        "    axs[0][0].set_title(\"Original Image\")\n",
        "    axs[0][0].axis('off')\n",
        "\n",
        "    # Display predicted masks\n",
        "    for i, cell_type in enumerate(CLASSES):\n",
        "        mask = predicted_masks[i]\n",
        "        mask_resized = cv2.resize(mask, (original_shape[1], original_shape[0]))\n",
        "        binary_mask = (mask_resized > threshold).astype(np.uint8)\n",
        "\n",
        "        colored_mask = np.zeros_like(image_rgb)\n",
        "        if cell_type == 'Epithelial':\n",
        "            color = (255, 0, 0) # Red\n",
        "        elif cell_type == 'Lymphocyte':\n",
        "            color = (0, 255, 0) # Green\n",
        "        elif cell_type == 'Neutrophil':\n",
        "            color = (0, 0, 255) # Blue\n",
        "        elif cell_type == 'Macrophage':\n",
        "            color = (255, 255, 0) # Yellow\n",
        "        colored_mask[binary_mask > 0] = color\n",
        "\n",
        "        overlaid_image = cv2.addWeighted(image_rgb, 1 - 0.5, colored_mask, 0.5, 0)\n",
        "        axs[0][i+1].imshow(overlaid_image)\n",
        "        axs[0][i+1].set_title(f'{cell_type} Predicted')\n",
        "        axs[0][i+1].axis('off')\n",
        "\n",
        "    # Remove axis from axs[0][0]\n",
        "    axs[0][0].axis('off')\n",
        "\n",
        "    # Display ground truth masks if available\n",
        "    if masks_ground_truth:\n",
        "        for i, cell_type in enumerate(CLASSES):\n",
        "            mask = masks_ground_truth[cell_type]\n",
        "\n",
        "            colored_mask = np.zeros_like(image_rgb)\n",
        "            if cell_type == 'Epithelial':\n",
        "                color = (255, 0, 0) # Red\n",
        "            elif cell_type == 'Lymphocyte':\n",
        "                color = (0, 255, 0) # Green\n",
        "            elif cell_type == 'Neutrophil':\n",
        "                color = (0, 0, 255) # Blue\n",
        "            elif cell_type == 'Macrophage':\n",
        "                color = (255, 255, 0) # Yellow\n",
        "            colored_mask[mask > 0] = color\n",
        "\n",
        "            overlaid_image = cv2.addWeighted(image_rgb, 1 - 0.5, colored_mask, 0.5, 0)\n",
        "            axs[1][1 + i].imshow(overlaid_image)\n",
        "            axs[1][1 + i].set_title(f'{cell_type} Ground Truth')\n",
        "            axs[1][1 + i].axis('off')\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfTePdLANYII"
      },
      "source": [
        "## Team Model\n",
        "\n",
        "We have iterated through a bunch of ideas here in order to try and improve performance. Below is a list of things that we did (and kept in the model) and below will be a list of things that were attempted but removed due to worsening performance.\n",
        "\n",
        "**Things that worked**\n",
        "\n",
        "1.  Utilize Deep Residual Learning [(He et al., 2015)](https://arxiv.org/abs/1512.03385) and using *pre-trained ResNet encoder* to improve feature detection. Here, we will use resnet-50 as part of our encoder structrue to take advantage of the pretrained weights that improve feature detection.\n",
        "\n",
        "Implementation steps: Resnet has\n",
        "many layers\n",
        "![Alt Text](https://towardsdatascience.com/wp-content/uploads/2022/08/0mQA4WKBXkvE-Atjn.png)\n",
        "\n",
        "\"Hijacking\" the model before the max pool\n",
        "\n",
        "2.  Utilize a combined loss function to improve performace. We can use a combined weighted sum of Binary Focal Loss along with the dice loss seen above. Binary Focal Loss will help eliminate false positives seen on previous iterations of the model. On the other hand the Dice loss acts as a corrective measure to pay attention to segmented cells (regardless of size), this can help improve boundaries of segmented objects (which Cross-Entropy struggles with).\n",
        "\n",
        "We will define a loss of: $$\\alpha \\times Loss_{FL} + \\beta \\times Loss_{Dice}$$ Where $\\alpha = 0.5$ and $\\beta = 0.5$\n",
        "\n",
        "3.  Change traditional decoder block structure on model. In the original Decoder Block structure it was suggested to use a convolutional transpose for upsampling, but this created a \"checkerboard\" pattern that is common from U-Net decoders. Since Conv2DTranspose is a learnable parameter, it would likely require more data to become as robust as the \"simple\" biliear upsampling.\n",
        "\n",
        "4.  Implement an attention based gate to remove cross-class contamination from Decoder Blocks. After running the previous examples, we ran into a problem where one of the other classes was better performant than the \"correct\" class. This implied that our current U-Net structure was forwarding all features from the encoder to the decoder, creting noisy/confusing features that made differentiation harder. To attemp to improve this, we can implement attention gates to the skip connections in order to supress irrelevant features and amplify relevant features. The idea for this improvement came from the 2018 paper \"Attention U-Net\" https://arxiv.org/pdf/1804.03999\n",
        "\n",
        "5.  Add rotation invariance to the model by augmenting the dataset to include rotations of the original data. U-Nets are not rotationally invariant by design, one thing we can do to compensate for this is by augmenting our data by adding rotated versions of the images in order to create different and new training data for the model to learn from.\n",
        "\n",
        "**Things that we tried and did not work**\n",
        "1.   INITIAL THOUGHTS: Utilize a combined loss function to improve performace. We can use a combined weighted sum of Cross Entropy loss along with the dice loss seen above. Since Cross-Entropy is a pixel-wise loss it will help us with stability, due to its smooth gradient and ensures the model handles background pixels efficiently. On the other hand the Dice loss acts as a corrective measure to pay attention to segmented cells (regardless of size), this can help improve boundaries of segmented objects (which Cross-Entropy struggles with).\n",
        "\n",
        "We will define a loss of: $$\\alpha \\times Loss_{CE} + \\beta \\times Loss_{Dice}$$ Where $\\alpha = 0.5$ and $\\beta = 0.5$\n",
        "\n",
        "Output: This yielded a lot of false positives which was not optimal for the problem. To fix this we are coing to try a Focal loss to treat all samples equally. We will use a comination of the focal loss and the dice loss next.\n",
        "\n",
        "\n",
        "Things left to test:\n",
        "https://arxiv.org/abs/2501.08458\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3z59IZuoVxn8"
      },
      "outputs": [],
      "source": [
        "import torchvision.models as models\n",
        "from torch.nn.modules.loss import CrossEntropyLoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwRUbjGQDZcR"
      },
      "outputs": [],
      "source": [
        "#Creating the AttentionGate\n",
        "class AttentionGate(nn.Module):\n",
        "    def __init__(self, g_channels, skip_channels, int_channels):\n",
        "        super(AttentionGate, self).__init__()\n",
        "\n",
        "        # Convolution for gating signal (in_channel)\n",
        "        self.weight_g = nn.Sequential(\n",
        "            nn.Conv2d(g_channels, int_channels, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(int_channels)\n",
        "        )\n",
        "\n",
        "        # Convoluion for the skip connection signal\n",
        "        self.weight_s = nn.Sequential(\n",
        "            nn.Conv2d(skip_channels, int_channels, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(int_channels)\n",
        "        )\n",
        "\n",
        "        # Layer to create 1-channel attention map\n",
        "        self.psi = nn.Sequential(\n",
        "            nn.Conv2d(int_channels, 1, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, g, skip):\n",
        "        # Process gating signal\n",
        "        g_out = self.weight_g(g)\n",
        "\n",
        "        # Process skip connection\n",
        "        s_out = self.weight_s(skip)\n",
        "\n",
        "        # Combine signals and apply ReLu activation\n",
        "        combined = self.relu(g_out + s_out)\n",
        "\n",
        "        # Create attention map\n",
        "        attention_map = self.psi(combined)\n",
        "\n",
        "        # Apply attention map to skip connection\n",
        "        return skip * attention_map\n",
        "\n",
        "\n",
        "# Here, in order to save time, we asked help of AI to help us manually build the resnet model into\n",
        "# the U-Net model.\n",
        "\n",
        "# Define a decoder block for our model\n",
        "# 1. Upsample the feature map from the previous (deeper) layers.\n",
        "# 2. Concatenate it with the skip connection from the encoder.\n",
        "# 3. Apply convolutions.\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, in_channels, skip_channels, out_channels):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "\n",
        "        # Use Convolutional transpose 2D for upsampling\n",
        "        # self.upconv = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
        "\n",
        "        # Use bilinear2d upscaling\n",
        "        self.upconv = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
        "            nn.Conv2d(in_channels, in_channels//2, kernel_size=1)\n",
        "        )\n",
        "\n",
        "        # Add new block for attention\n",
        "        g_channels = in_channels // 2\n",
        "        skip_channels = skip_channels\n",
        "        int_channels = in_channels // 2\n",
        "\n",
        "        # Define self attention gate\n",
        "        self.attention_gate = AttentionGate(g_channels=g_channels, skip_channels=skip_channels, int_channels=int_channels)\n",
        "\n",
        "        # 3x3 convolution block after concatenation\n",
        "        # Input channels = (channels from upsampled layer) + (channels from skip connection)\n",
        "        self.conv_block = nn.Sequential(\n",
        "            nn.Conv2d(in_channels // 2 + skip_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    # Define forward pass\n",
        "    def forward(self, x_deep, x_skip):\n",
        "        x_upsampled = self.upconv(x_deep)\n",
        "\n",
        "        # Apply attention gate to skip connection\n",
        "        s_filtered = self.attention_gate(x_upsampled, x_skip)\n",
        "\n",
        "        # Concatenate the upsmpled signal wit hteh filtered skip signal\n",
        "        #   Without attention it was torch.cat([x, x_skip], dim=1)\n",
        "        x = torch.cat([x_upsampled, s_filtered], dim=1)\n",
        "\n",
        "        # Apply final convolutions\n",
        "        x = self.conv_block(x)\n",
        "        return x\n",
        "\n",
        "# Define full ResNet-U-Neet Model\n",
        "class ResNetUNet(nn.Module):\n",
        "    def __init__(self, num_classes=4):\n",
        "        super(ResNetUNet, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.resnet = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "\n",
        "        # Utilize ResNet layers, stopping before the final AvgPool and FC layers\n",
        "        # These are our encoder blocks\n",
        "        self.enc_init = nn.Sequential(\n",
        "            self.resnet.conv1,\n",
        "            self.resnet.bn1,\n",
        "            self.resnet.relu,\n",
        "        ) # Output channels: 64\n",
        "\n",
        "        self.enc_pool = self.resnet.maxpool # Output channels: 64\n",
        "        self.enc1 = self.resnet.layer1 # Output channels: 256\n",
        "        self.enc2 = self.resnet.layer2 # Output channels: 512\n",
        "        self.enc3 = self.resnet.layer3 # Output channels: 1024\n",
        "\n",
        "        # Set bottleneck as transition between\n",
        "        self.bottleneck = self.resnet.layer4 # Output channels: 2048\n",
        "\n",
        "        # Decoder\n",
        "        # Cannel counts are chosen to match ResNet skip connections\n",
        "        # i.e. (2048, 1024, 512, 256, 64)\n",
        "\n",
        "        self.dec_block3 = DecoderBlock(in_channels=2048, skip_channels=1024, out_channels=1024)\n",
        "        self.dec_block2 = DecoderBlock(in_channels=1024, skip_channels=512, out_channels=512)\n",
        "        self.dec_block1 = DecoderBlock(in_channels=512, skip_channels=256, out_channels=256)\n",
        "        self.dec_block0 = DecoderBlock(in_channels=256, skip_channels=64, out_channels=128)\n",
        "\n",
        "        # Add an extra upsampling block to match the initial layer\n",
        "        self.dec_final_up = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Create final output layer for our classes (map from 64 to num_classes)\n",
        "        self.final_conv = nn.Conv2d(64, num_classes, kernel_size=1)\n",
        "\n",
        "    # Designate forward pass\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        # We save the output of each stage to use as skip connection\n",
        "        x_init = self.enc_init(x)\n",
        "        x_pool = self.enc_pool(x_init)\n",
        "        x_enc1 = self.enc1(x_pool)\n",
        "        x_enc2 = self.enc2(x_enc1)\n",
        "        x_enc3 = self.enc3(x_enc2)\n",
        "\n",
        "        # Bottleneck\n",
        "        x_bottleneck = self.bottleneck(x_enc3)\n",
        "\n",
        "        # Decoder\n",
        "        x_dec3 = self.dec_block3(x_bottleneck, x_enc3)\n",
        "        x_dec2 = self.dec_block2(x_dec3, x_enc2)\n",
        "        x_dec1 = self.dec_block1(x_dec2, x_enc1)\n",
        "        x_dec0 = self.dec_block0(x_dec1, x_init)\n",
        "\n",
        "        # Match block to s_init shape (although we do not use skip connection)\n",
        "        x_final_up = self.dec_final_up(x_dec0)\n",
        "\n",
        "        out = self.final_conv(x_final_up)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SH2uTKs03Sj"
      },
      "outputs": [],
      "source": [
        "class BinaryFocalLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements Binary Focal Loss (for multi-label tasks)\n",
        "    This loss is applied per-channel, where each channel is a binary (Yes/No) task.\n",
        "    \"\"\"\n",
        "    def __init__(self, gamma=2.0, alpha=0.25, reduction='mean'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            gamma (float, optional): Focusing parameter. Defaults to 2.0.\n",
        "            alpha (float, optional): Weighting factor for the positive class (e.g., 0.25).\n",
        "                                     This is different from the multi-class alpha.\n",
        "            reduction (str, optional): 'mean', 'sum', or 'none'. Defaults to 'mean'.\n",
        "        \"\"\"\n",
        "        super(BinaryFocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            logits (torch.Tensor): Model output (B, C_foreground, H, W)\n",
        "            targets (torch.Tensor): Target mask (B, H, W) containing class indices or (B, C_foreground, H, W)\n",
        "        \"\"\"\n",
        "        # Ensure targets have the same number of dimensions as logits for per-channel BCE\n",
        "        # If targets are (B, H, W) (class indices), expand to (B, 1, H, W) and then match channel dim of logits\n",
        "        if targets.dim() == 3:\n",
        "             # This assumes targets contain class indices (0 for background, 1..C for classes)\n",
        "             # Convert class indices to one-hot encoding matching the foreground channels\n",
        "             # Note: This assumes the model outputs probabilities/logits for foreground classes only\n",
        "             # and the target indices correspond to these foreground classes (1..C maps to channels 0..C-1)\n",
        "             target_one_hot = torch.zeros_like(logits)\n",
        "             for i in range(logits.shape[1]):\n",
        "                 target_one_hot[:, i, :, :] = (targets == (i + 1)).float() # Map index i+1 to channel i\n",
        "             targets = target_one_hot\n",
        "\n",
        "\n",
        "        # Calculate BCEWithLogitsLoss (this is numerically stable)\n",
        "        bce_loss = F.binary_cross_entropy_with_logits(logits, targets, reduction='none')\n",
        "\n",
        "        # Get probabilities\n",
        "        probs = torch.sigmoid(logits)\n",
        "\n",
        "        # Calculate pt\n",
        "        # If target is 1, pt = p. If target is 0, pt = 1-p.\n",
        "        pt = targets * probs + (1 - targets) * (1 - probs)\n",
        "\n",
        "        # Calculate modulating factor\n",
        "        modulating_factor = (1.0 - pt).pow(self.gamma)\n",
        "\n",
        "        # Calculate alpha_t\n",
        "        # If target is 1, alpha_t = alpha. If target is 0, alpha_t = 1-alpha.\n",
        "        # Apply alpha per channel based on the target mask\n",
        "        alpha_t = self.alpha * targets + (1 - self.alpha) * (1 - targets)\n",
        "\n",
        "\n",
        "        # Calculate final focal loss\n",
        "        focal_loss = alpha_t * modulating_factor * bce_loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        else:\n",
        "            return focal_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bf3_qNysifVY"
      },
      "outputs": [],
      "source": [
        "def train_model_team(model, train_loader, num_epochs, device, alpha=0.5, beta=0.5):\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Freezing Resnet encoder weights\n",
        "    for param in model.enc_init.parameters():\n",
        "        param.requires_grad = False\n",
        "    for param in model.enc_pool.parameters():\n",
        "        param.requires_grad = False\n",
        "    for param in model.enc1.parameters():\n",
        "        param.requires_grad = False\n",
        "    for param in model.enc2.parameters():\n",
        "        param.requires_grad = False\n",
        "    for param in model.enc3.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "    binary_focal_loss = BinaryFocalLoss()\n",
        "\n",
        "    print(f\"\\nTraining on {device}\")\n",
        "\n",
        "    train_loss = []\n",
        "    best_performance = np.inf\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "\n",
        "        for batch_idx, batch in enumerate(train_loader):\n",
        "            images = batch['image'].to(device)\n",
        "            masks = batch['mask'].to(device) # Shape (B, C, H, W)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images) # Shape (B, C, H, W)\n",
        "\n",
        "            # Convert multi-channel masks to a single channel with class indices for CrossEntropyLoss\n",
        "            # The masks tensor has shape (batch_size, num_classes, H, W)\n",
        "            # We want a tensor of shape (batch_size, H, W) where each element is the class index\n",
        "            # Find the class index for each pixel by finding the channel with a value > 0\n",
        "            # If a pixel is 0 across all channels, it's background (class 0 implicitly)\n",
        "            # target_ce = torch.argmax(masks, dim=1).long() # This creates (B, H, W)\n",
        "\n",
        "            # DiceLoss expects probabilities (sigmoid or softmax) and the multi-channel mask\n",
        "            # BinaryFocalLoss is designed to work on multi-channel output and expects a multi-channel target mask (B, C, H, W)\n",
        "            # Pass the original masks tensor directly to BinaryFocalLoss\n",
        "            loss = alpha * dice_loss(torch.sigmoid(outputs), masks) + beta * binary_focal_loss(outputs, masks)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            if batch_idx % 5 == 0:\n",
        "                print(f\"Epoch [{epoch+1}/{num_epochs}] Batch [{batch_idx}/{len(train_loader)}] Loss: {loss.item():.4f}\")\n",
        "\n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "        train_loss.append(avg_loss)\n",
        "        if avg_loss < best_performance:\n",
        "            best_performance = avg_loss\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] Avg Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfSR_IIykPrr",
        "outputId": "205f117c-5012-42e0-cc9b-56a7bb951fad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating dataset...\n",
            "Train samples: 209\n",
            "\n",
            "Creating model...\n",
            "Parameters: 68,707,064\n",
            "\n",
            "Training...\n",
            "\n",
            "Training on cuda\n",
            "Epoch [1/30] Batch [0/53] Loss: 0.5554\n",
            "Epoch [1/30] Batch [5/53] Loss: 0.5168\n",
            "Epoch [1/30] Batch [10/53] Loss: 0.5190\n",
            "Epoch [1/30] Batch [15/53] Loss: 0.4983\n",
            "Epoch [1/30] Batch [20/53] Loss: 0.4797\n",
            "Epoch [1/30] Batch [25/53] Loss: 0.4666\n",
            "Epoch [1/30] Batch [30/53] Loss: 0.4820\n",
            "Epoch [1/30] Batch [35/53] Loss: 0.4819\n",
            "Epoch [1/30] Batch [40/53] Loss: 0.4770\n",
            "Epoch [1/30] Batch [45/53] Loss: 0.4817\n",
            "Epoch [1/30] Batch [50/53] Loss: 0.4584\n",
            "Epoch [1/30] Avg Loss: 0.4901\n",
            "Epoch [2/30] Batch [0/53] Loss: 0.4720\n",
            "Epoch [2/30] Batch [5/53] Loss: 0.4642\n",
            "Epoch [2/30] Batch [10/53] Loss: 0.4829\n",
            "Epoch [2/30] Batch [15/53] Loss: 0.4651\n",
            "Epoch [2/30] Batch [20/53] Loss: 0.4601\n",
            "Epoch [2/30] Batch [25/53] Loss: 0.4728\n",
            "Epoch [2/30] Batch [30/53] Loss: 0.4596\n",
            "Epoch [2/30] Batch [35/53] Loss: 0.4486\n",
            "Epoch [2/30] Batch [40/53] Loss: 0.4508\n",
            "Epoch [2/30] Batch [45/53] Loss: 0.4528\n",
            "Epoch [2/30] Batch [50/53] Loss: 0.4763\n",
            "Epoch [2/30] Avg Loss: 0.4653\n",
            "Epoch [3/30] Batch [0/53] Loss: 0.4681\n",
            "Epoch [3/30] Batch [5/53] Loss: 0.4456\n",
            "Epoch [3/30] Batch [10/53] Loss: 0.4699\n",
            "Epoch [3/30] Batch [15/53] Loss: 0.4417\n",
            "Epoch [3/30] Batch [20/53] Loss: 0.4572\n",
            "Epoch [3/30] Batch [25/53] Loss: 0.4544\n",
            "Epoch [3/30] Batch [30/53] Loss: 0.4520\n",
            "Epoch [3/30] Batch [35/53] Loss: 0.4236\n",
            "Epoch [3/30] Batch [40/53] Loss: 0.4632\n",
            "Epoch [3/30] Batch [45/53] Loss: 0.4405\n",
            "Epoch [3/30] Batch [50/53] Loss: 0.4556\n",
            "Epoch [3/30] Avg Loss: 0.4519\n",
            "Epoch [4/30] Batch [0/53] Loss: 0.4449\n",
            "Epoch [4/30] Batch [5/53] Loss: 0.4474\n",
            "Epoch [4/30] Batch [10/53] Loss: 0.4412\n",
            "Epoch [4/30] Batch [15/53] Loss: 0.4279\n",
            "Epoch [4/30] Batch [20/53] Loss: 0.4310\n",
            "Epoch [4/30] Batch [25/53] Loss: 0.4305\n",
            "Epoch [4/30] Batch [30/53] Loss: 0.4647\n",
            "Epoch [4/30] Batch [35/53] Loss: 0.4438\n",
            "Epoch [4/30] Batch [40/53] Loss: 0.4474\n",
            "Epoch [4/30] Batch [45/53] Loss: 0.4337\n",
            "Epoch [4/30] Batch [50/53] Loss: 0.4437\n",
            "Epoch [4/30] Avg Loss: 0.4425\n",
            "Epoch [5/30] Batch [0/53] Loss: 0.4233\n",
            "Epoch [5/30] Batch [5/53] Loss: 0.4367\n",
            "Epoch [5/30] Batch [10/53] Loss: 0.4248\n",
            "Epoch [5/30] Batch [15/53] Loss: 0.4334\n",
            "Epoch [5/30] Batch [20/53] Loss: 0.4290\n",
            "Epoch [5/30] Batch [25/53] Loss: 0.4370\n",
            "Epoch [5/30] Batch [30/53] Loss: 0.4461\n",
            "Epoch [5/30] Batch [35/53] Loss: 0.4483\n",
            "Epoch [5/30] Batch [40/53] Loss: 0.4176\n",
            "Epoch [5/30] Batch [45/53] Loss: 0.4323\n",
            "Epoch [5/30] Batch [50/53] Loss: 0.4332\n",
            "Epoch [5/30] Avg Loss: 0.4319\n",
            "Epoch [6/30] Batch [0/53] Loss: 0.4516\n",
            "Epoch [6/30] Batch [5/53] Loss: 0.4268\n",
            "Epoch [6/30] Batch [10/53] Loss: 0.4330\n",
            "Epoch [6/30] Batch [15/53] Loss: 0.4317\n",
            "Epoch [6/30] Batch [20/53] Loss: 0.4173\n",
            "Epoch [6/30] Batch [25/53] Loss: 0.4243\n",
            "Epoch [6/30] Batch [30/53] Loss: 0.4202\n",
            "Epoch [6/30] Batch [35/53] Loss: 0.4159\n",
            "Epoch [6/30] Batch [40/53] Loss: 0.4217\n",
            "Epoch [6/30] Batch [45/53] Loss: 0.4433\n",
            "Epoch [6/30] Batch [50/53] Loss: 0.4161\n",
            "Epoch [6/30] Avg Loss: 0.4296\n",
            "Epoch [7/30] Batch [0/53] Loss: 0.4181\n",
            "Epoch [7/30] Batch [5/53] Loss: 0.4183\n",
            "Epoch [7/30] Batch [10/53] Loss: 0.4026\n",
            "Epoch [7/30] Batch [15/53] Loss: 0.4432\n",
            "Epoch [7/30] Batch [20/53] Loss: 0.4112\n",
            "Epoch [7/30] Batch [25/53] Loss: 0.4448\n",
            "Epoch [7/30] Batch [30/53] Loss: 0.4204\n",
            "Epoch [7/30] Batch [35/53] Loss: 0.4091\n",
            "Epoch [7/30] Batch [40/53] Loss: 0.4197\n",
            "Epoch [7/30] Batch [45/53] Loss: 0.4476\n",
            "Epoch [7/30] Batch [50/53] Loss: 0.4212\n",
            "Epoch [7/30] Avg Loss: 0.4245\n",
            "Epoch [8/30] Batch [0/53] Loss: 0.4403\n",
            "Epoch [8/30] Batch [5/53] Loss: 0.4126\n",
            "Epoch [8/30] Batch [10/53] Loss: 0.4161\n",
            "Epoch [8/30] Batch [15/53] Loss: 0.4070\n",
            "Epoch [8/30] Batch [20/53] Loss: 0.3943\n",
            "Epoch [8/30] Batch [25/53] Loss: 0.4019\n",
            "Epoch [8/30] Batch [30/53] Loss: 0.4183\n",
            "Epoch [8/30] Batch [35/53] Loss: 0.3946\n",
            "Epoch [8/30] Batch [40/53] Loss: 0.4152\n",
            "Epoch [8/30] Batch [45/53] Loss: 0.4375\n",
            "Epoch [8/30] Batch [50/53] Loss: 0.4495\n",
            "Epoch [8/30] Avg Loss: 0.4202\n",
            "Epoch [9/30] Batch [0/53] Loss: 0.4179\n",
            "Epoch [9/30] Batch [5/53] Loss: 0.4140\n",
            "Epoch [9/30] Batch [10/53] Loss: 0.4108\n",
            "Epoch [9/30] Batch [15/53] Loss: 0.4216\n",
            "Epoch [9/30] Batch [20/53] Loss: 0.4213\n",
            "Epoch [9/30] Batch [25/53] Loss: 0.4565\n",
            "Epoch [9/30] Batch [30/53] Loss: 0.4329\n",
            "Epoch [9/30] Batch [35/53] Loss: 0.4708\n",
            "Epoch [9/30] Batch [40/53] Loss: 0.4153\n",
            "Epoch [9/30] Batch [45/53] Loss: 0.3835\n",
            "Epoch [9/30] Batch [50/53] Loss: 0.4200\n",
            "Epoch [9/30] Avg Loss: 0.4174\n",
            "Epoch [10/30] Batch [0/53] Loss: 0.3966\n",
            "Epoch [10/30] Batch [5/53] Loss: 0.4240\n",
            "Epoch [10/30] Batch [10/53] Loss: 0.4158\n",
            "Epoch [10/30] Batch [15/53] Loss: 0.3970\n",
            "Epoch [10/30] Batch [20/53] Loss: 0.4020\n",
            "Epoch [10/30] Batch [25/53] Loss: 0.4162\n",
            "Epoch [10/30] Batch [30/53] Loss: 0.4115\n",
            "Epoch [10/30] Batch [35/53] Loss: 0.3948\n",
            "Epoch [10/30] Batch [40/53] Loss: 0.4400\n",
            "Epoch [10/30] Batch [45/53] Loss: 0.3700\n",
            "Epoch [10/30] Batch [50/53] Loss: 0.4084\n",
            "Epoch [10/30] Avg Loss: 0.4148\n",
            "Epoch [11/30] Batch [0/53] Loss: 0.4231\n",
            "Epoch [11/30] Batch [5/53] Loss: 0.4486\n",
            "Epoch [11/30] Batch [10/53] Loss: 0.4642\n",
            "Epoch [11/30] Batch [15/53] Loss: 0.3992\n",
            "Epoch [11/30] Batch [20/53] Loss: 0.4005\n",
            "Epoch [11/30] Batch [25/53] Loss: 0.4007\n",
            "Epoch [11/30] Batch [30/53] Loss: 0.4157\n",
            "Epoch [11/30] Batch [35/53] Loss: 0.4195\n",
            "Epoch [11/30] Batch [40/53] Loss: 0.4218\n",
            "Epoch [11/30] Batch [45/53] Loss: 0.4152\n",
            "Epoch [11/30] Batch [50/53] Loss: 0.4071\n",
            "Epoch [11/30] Avg Loss: 0.4125\n",
            "Epoch [12/30] Batch [0/53] Loss: 0.4269\n",
            "Epoch [12/30] Batch [5/53] Loss: 0.4126\n",
            "Epoch [12/30] Batch [10/53] Loss: 0.3654\n",
            "Epoch [12/30] Batch [15/53] Loss: 0.4438\n",
            "Epoch [12/30] Batch [20/53] Loss: 0.4132\n",
            "Epoch [12/30] Batch [25/53] Loss: 0.4283\n",
            "Epoch [12/30] Batch [30/53] Loss: 0.3845\n",
            "Epoch [12/30] Batch [35/53] Loss: 0.4232\n",
            "Epoch [12/30] Batch [40/53] Loss: 0.3888\n",
            "Epoch [12/30] Batch [45/53] Loss: 0.4130\n",
            "Epoch [12/30] Batch [50/53] Loss: 0.4077\n",
            "Epoch [12/30] Avg Loss: 0.4107\n",
            "Epoch [13/30] Batch [0/53] Loss: 0.4089\n",
            "Epoch [13/30] Batch [5/53] Loss: 0.4214\n",
            "Epoch [13/30] Batch [10/53] Loss: 0.4326\n",
            "Epoch [13/30] Batch [15/53] Loss: 0.4163\n",
            "Epoch [13/30] Batch [20/53] Loss: 0.3805\n",
            "Epoch [13/30] Batch [25/53] Loss: 0.3931\n",
            "Epoch [13/30] Batch [30/53] Loss: 0.3989\n",
            "Epoch [13/30] Batch [35/53] Loss: 0.4176\n",
            "Epoch [13/30] Batch [40/53] Loss: 0.4296\n",
            "Epoch [13/30] Batch [45/53] Loss: 0.4515\n",
            "Epoch [13/30] Batch [50/53] Loss: 0.4021\n",
            "Epoch [13/30] Avg Loss: 0.4073\n",
            "Epoch [14/30] Batch [0/53] Loss: 0.4183\n",
            "Epoch [14/30] Batch [5/53] Loss: 0.3812\n",
            "Epoch [14/30] Batch [10/53] Loss: 0.4224\n",
            "Epoch [14/30] Batch [15/53] Loss: 0.4060\n",
            "Epoch [14/30] Batch [20/53] Loss: 0.3934\n",
            "Epoch [14/30] Batch [25/53] Loss: 0.3846\n",
            "Epoch [14/30] Batch [30/53] Loss: 0.3965\n",
            "Epoch [14/30] Batch [35/53] Loss: 0.4096\n",
            "Epoch [14/30] Batch [40/53] Loss: 0.4198\n",
            "Epoch [14/30] Batch [45/53] Loss: 0.4184\n",
            "Epoch [14/30] Batch [50/53] Loss: 0.4124\n",
            "Epoch [14/30] Avg Loss: 0.4075\n",
            "Epoch [15/30] Batch [0/53] Loss: 0.3987\n",
            "Epoch [15/30] Batch [5/53] Loss: 0.4097\n",
            "Epoch [15/30] Batch [10/53] Loss: 0.3756\n",
            "Epoch [15/30] Batch [15/53] Loss: 0.4257\n",
            "Epoch [15/30] Batch [20/53] Loss: 0.4023\n",
            "Epoch [15/30] Batch [25/53] Loss: 0.4137\n",
            "Epoch [15/30] Batch [30/53] Loss: 0.4194\n",
            "Epoch [15/30] Batch [35/53] Loss: 0.4338\n",
            "Epoch [15/30] Batch [40/53] Loss: 0.4150\n",
            "Epoch [15/30] Batch [45/53] Loss: 0.3993\n",
            "Epoch [15/30] Batch [50/53] Loss: 0.3964\n",
            "Epoch [15/30] Avg Loss: 0.4040\n",
            "Epoch [16/30] Batch [0/53] Loss: 0.4169\n",
            "Epoch [16/30] Batch [5/53] Loss: 0.4122\n",
            "Epoch [16/30] Batch [10/53] Loss: 0.3881\n",
            "Epoch [16/30] Batch [15/53] Loss: 0.3788\n",
            "Epoch [16/30] Batch [20/53] Loss: 0.4197\n",
            "Epoch [16/30] Batch [25/53] Loss: 0.3989\n",
            "Epoch [16/30] Batch [30/53] Loss: 0.4203\n",
            "Epoch [16/30] Batch [35/53] Loss: 0.3881\n",
            "Epoch [16/30] Batch [40/53] Loss: 0.3913\n",
            "Epoch [16/30] Batch [45/53] Loss: 0.3976\n",
            "Epoch [16/30] Batch [50/53] Loss: 0.3757\n",
            "Epoch [16/30] Avg Loss: 0.4002\n",
            "Epoch [17/30] Batch [0/53] Loss: 0.4080\n",
            "Epoch [17/30] Batch [5/53] Loss: 0.4089\n",
            "Epoch [17/30] Batch [10/53] Loss: 0.4082\n",
            "Epoch [17/30] Batch [15/53] Loss: 0.3794\n",
            "Epoch [17/30] Batch [20/53] Loss: 0.4152\n",
            "Epoch [17/30] Batch [25/53] Loss: 0.4191\n",
            "Epoch [17/30] Batch [30/53] Loss: 0.4313\n",
            "Epoch [17/30] Batch [35/53] Loss: 0.3990\n",
            "Epoch [17/30] Batch [40/53] Loss: 0.4124\n",
            "Epoch [17/30] Batch [45/53] Loss: 0.4175\n",
            "Epoch [17/30] Batch [50/53] Loss: 0.4039\n",
            "Epoch [17/30] Avg Loss: 0.3971\n",
            "Epoch [18/30] Batch [0/53] Loss: 0.3840\n",
            "Epoch [18/30] Batch [5/53] Loss: 0.3916\n",
            "Epoch [18/30] Batch [10/53] Loss: 0.3943\n",
            "Epoch [18/30] Batch [15/53] Loss: 0.3842\n",
            "Epoch [18/30] Batch [20/53] Loss: 0.4011\n",
            "Epoch [18/30] Batch [25/53] Loss: 0.4262\n",
            "Epoch [18/30] Batch [30/53] Loss: 0.3764\n",
            "Epoch [18/30] Batch [35/53] Loss: 0.4853\n",
            "Epoch [18/30] Batch [40/53] Loss: 0.4321\n",
            "Epoch [18/30] Batch [45/53] Loss: 0.4494\n",
            "Epoch [18/30] Batch [50/53] Loss: 0.4083\n",
            "Epoch [18/30] Avg Loss: 0.3972\n",
            "Epoch [19/30] Batch [0/53] Loss: 0.4012\n",
            "Epoch [19/30] Batch [5/53] Loss: 0.4328\n",
            "Epoch [19/30] Batch [10/53] Loss: 0.3678\n",
            "Epoch [19/30] Batch [15/53] Loss: 0.4185\n",
            "Epoch [19/30] Batch [20/53] Loss: 0.3740\n",
            "Epoch [19/30] Batch [25/53] Loss: 0.4187\n",
            "Epoch [19/30] Batch [30/53] Loss: 0.3556\n",
            "Epoch [19/30] Batch [35/53] Loss: 0.4110\n",
            "Epoch [19/30] Batch [40/53] Loss: 0.4013\n",
            "Epoch [19/30] Batch [45/53] Loss: 0.3881\n",
            "Epoch [19/30] Batch [50/53] Loss: 0.3816\n",
            "Epoch [19/30] Avg Loss: 0.3934\n",
            "Epoch [20/30] Batch [0/53] Loss: 0.3571\n",
            "Epoch [20/30] Batch [5/53] Loss: 0.3826\n",
            "Epoch [20/30] Batch [10/53] Loss: 0.3980\n",
            "Epoch [20/30] Batch [15/53] Loss: 0.4088\n",
            "Epoch [20/30] Batch [20/53] Loss: 0.4053\n",
            "Epoch [20/30] Batch [25/53] Loss: 0.4010\n",
            "Epoch [20/30] Batch [30/53] Loss: 0.4129\n",
            "Epoch [20/30] Batch [35/53] Loss: 0.4074\n",
            "Epoch [20/30] Batch [40/53] Loss: 0.4060\n",
            "Epoch [20/30] Batch [45/53] Loss: 0.4423\n",
            "Epoch [20/30] Batch [50/53] Loss: 0.4151\n",
            "Epoch [20/30] Avg Loss: 0.3976\n",
            "Epoch [21/30] Batch [0/53] Loss: 0.4356\n",
            "Epoch [21/30] Batch [5/53] Loss: 0.3881\n",
            "Epoch [21/30] Batch [10/53] Loss: 0.4027\n",
            "Epoch [21/30] Batch [15/53] Loss: 0.3681\n",
            "Epoch [21/30] Batch [20/53] Loss: 0.3706\n",
            "Epoch [21/30] Batch [25/53] Loss: 0.3616\n",
            "Epoch [21/30] Batch [30/53] Loss: 0.4207\n",
            "Epoch [21/30] Batch [35/53] Loss: 0.4116\n",
            "Epoch [21/30] Batch [40/53] Loss: 0.3893\n",
            "Epoch [21/30] Batch [45/53] Loss: 0.3955\n",
            "Epoch [21/30] Batch [50/53] Loss: 0.4233\n",
            "Epoch [21/30] Avg Loss: 0.3962\n",
            "Epoch [22/30] Batch [0/53] Loss: 0.4231\n",
            "Epoch [22/30] Batch [5/53] Loss: 0.4195\n",
            "Epoch [22/30] Batch [10/53] Loss: 0.4047\n",
            "Epoch [22/30] Batch [15/53] Loss: 0.3896\n",
            "Epoch [22/30] Batch [20/53] Loss: 0.3577\n",
            "Epoch [22/30] Batch [25/53] Loss: 0.3907\n",
            "Epoch [22/30] Batch [30/53] Loss: 0.4183\n",
            "Epoch [22/30] Batch [35/53] Loss: 0.4157\n",
            "Epoch [22/30] Batch [40/53] Loss: 0.3861\n",
            "Epoch [22/30] Batch [45/53] Loss: 0.3787\n",
            "Epoch [22/30] Batch [50/53] Loss: 0.4263\n",
            "Epoch [22/30] Avg Loss: 0.3967\n",
            "Epoch [23/30] Batch [0/53] Loss: 0.4001\n",
            "Epoch [23/30] Batch [5/53] Loss: 0.3846\n",
            "Epoch [23/30] Batch [10/53] Loss: 0.4001\n",
            "Epoch [23/30] Batch [15/53] Loss: 0.4060\n",
            "Epoch [23/30] Batch [20/53] Loss: 0.3545\n",
            "Epoch [23/30] Batch [25/53] Loss: 0.3983\n",
            "Epoch [23/30] Batch [30/53] Loss: 0.3990\n",
            "Epoch [23/30] Batch [35/53] Loss: 0.4011\n",
            "Epoch [23/30] Batch [40/53] Loss: 0.4024\n",
            "Epoch [23/30] Batch [45/53] Loss: 0.3889\n",
            "Epoch [23/30] Batch [50/53] Loss: 0.3865\n",
            "Epoch [23/30] Avg Loss: 0.3917\n",
            "Epoch [24/30] Batch [0/53] Loss: 0.3868\n",
            "Epoch [24/30] Batch [5/53] Loss: 0.3865\n",
            "Epoch [24/30] Batch [10/53] Loss: 0.4189\n",
            "Epoch [24/30] Batch [15/53] Loss: 0.3789\n",
            "Epoch [24/30] Batch [20/53] Loss: 0.3711\n",
            "Epoch [24/30] Batch [25/53] Loss: 0.4154\n",
            "Epoch [24/30] Batch [30/53] Loss: 0.3695\n",
            "Epoch [24/30] Batch [35/53] Loss: 0.3443\n",
            "Epoch [24/30] Batch [40/53] Loss: 0.4174\n",
            "Epoch [24/30] Batch [45/53] Loss: 0.3886\n",
            "Epoch [24/30] Batch [50/53] Loss: 0.3315\n",
            "Epoch [24/30] Avg Loss: 0.3924\n",
            "Epoch [25/30] Batch [0/53] Loss: 0.4099\n",
            "Epoch [25/30] Batch [5/53] Loss: 0.4025\n",
            "Epoch [25/30] Batch [10/53] Loss: 0.3886\n",
            "Epoch [25/30] Batch [15/53] Loss: 0.3777\n",
            "Epoch [25/30] Batch [20/53] Loss: 0.4065\n",
            "Epoch [25/30] Batch [25/53] Loss: 0.3789\n",
            "Epoch [25/30] Batch [30/53] Loss: 0.4190\n",
            "Epoch [25/30] Batch [35/53] Loss: 0.3906\n",
            "Epoch [25/30] Batch [40/53] Loss: 0.4153\n",
            "Epoch [25/30] Batch [45/53] Loss: 0.3683\n",
            "Epoch [25/30] Batch [50/53] Loss: 0.4113\n",
            "Epoch [25/30] Avg Loss: 0.3932\n",
            "Epoch [26/30] Batch [0/53] Loss: 0.3558\n",
            "Epoch [26/30] Batch [5/53] Loss: 0.3867\n",
            "Epoch [26/30] Batch [10/53] Loss: 0.4371\n",
            "Epoch [26/30] Batch [15/53] Loss: 0.4025\n",
            "Epoch [26/30] Batch [20/53] Loss: 0.3621\n",
            "Epoch [26/30] Batch [25/53] Loss: 0.4208\n",
            "Epoch [26/30] Batch [30/53] Loss: 0.3639\n",
            "Epoch [26/30] Batch [35/53] Loss: 0.3843\n",
            "Epoch [26/30] Batch [40/53] Loss: 0.4219\n",
            "Epoch [26/30] Batch [45/53] Loss: 0.4319\n",
            "Epoch [26/30] Batch [50/53] Loss: 0.3535\n",
            "Epoch [26/30] Avg Loss: 0.3895\n",
            "Epoch [27/30] Batch [0/53] Loss: 0.3664\n",
            "Epoch [27/30] Batch [5/53] Loss: 0.4342\n",
            "Epoch [27/30] Batch [10/53] Loss: 0.4050\n",
            "Epoch [27/30] Batch [15/53] Loss: 0.3540\n",
            "Epoch [27/30] Batch [20/53] Loss: 0.4118\n",
            "Epoch [27/30] Batch [25/53] Loss: 0.3393\n",
            "Epoch [27/30] Batch [30/53] Loss: 0.3653\n",
            "Epoch [27/30] Batch [35/53] Loss: 0.3980\n",
            "Epoch [27/30] Batch [40/53] Loss: 0.3865\n",
            "Epoch [27/30] Batch [45/53] Loss: 0.3874\n",
            "Epoch [27/30] Batch [50/53] Loss: 0.3993\n",
            "Epoch [27/30] Avg Loss: 0.3870\n",
            "Epoch [28/30] Batch [0/53] Loss: 0.3750\n",
            "Epoch [28/30] Batch [5/53] Loss: 0.3552\n",
            "Epoch [28/30] Batch [10/53] Loss: 0.3871\n",
            "Epoch [28/30] Batch [15/53] Loss: 0.3585\n",
            "Epoch [28/30] Batch [20/53] Loss: 0.3991\n",
            "Epoch [28/30] Batch [25/53] Loss: 0.4138\n",
            "Epoch [28/30] Batch [30/53] Loss: 0.3266\n",
            "Epoch [28/30] Batch [35/53] Loss: 0.3858\n",
            "Epoch [28/30] Batch [40/53] Loss: 0.3817\n",
            "Epoch [28/30] Batch [45/53] Loss: 0.3260\n",
            "Epoch [28/30] Batch [50/53] Loss: 0.3800\n",
            "Epoch [28/30] Avg Loss: 0.3832\n",
            "Epoch [29/30] Batch [0/53] Loss: 0.4305\n",
            "Epoch [29/30] Batch [5/53] Loss: 0.4283\n",
            "Epoch [29/30] Batch [10/53] Loss: 0.3932\n",
            "Epoch [29/30] Batch [15/53] Loss: 0.3648\n",
            "Epoch [29/30] Batch [20/53] Loss: 0.3749\n",
            "Epoch [29/30] Batch [25/53] Loss: 0.4241\n",
            "Epoch [29/30] Batch [30/53] Loss: 0.3325\n",
            "Epoch [29/30] Batch [35/53] Loss: 0.3983\n",
            "Epoch [29/30] Batch [40/53] Loss: 0.3965\n",
            "Epoch [29/30] Batch [45/53] Loss: 0.4168\n",
            "Epoch [29/30] Batch [50/53] Loss: 0.4202\n",
            "Epoch [29/30] Avg Loss: 0.3860\n",
            "Epoch [30/30] Batch [0/53] Loss: 0.3578\n",
            "Epoch [30/30] Batch [5/53] Loss: 0.3841\n",
            "Epoch [30/30] Batch [10/53] Loss: 0.3446\n",
            "Epoch [30/30] Batch [15/53] Loss: 0.3975\n",
            "Epoch [30/30] Batch [20/53] Loss: 0.3942\n",
            "Epoch [30/30] Batch [25/53] Loss: 0.3508\n",
            "Epoch [30/30] Batch [30/53] Loss: 0.4057\n",
            "Epoch [30/30] Batch [35/53] Loss: 0.4018\n",
            "Epoch [30/30] Batch [40/53] Loss: 0.3630\n",
            "Epoch [30/30] Batch [45/53] Loss: 0.4039\n",
            "Epoch [30/30] Batch [50/53] Loss: 0.3903\n",
            "Epoch [30/30] Avg Loss: 0.3851\n"
          ]
        }
      ],
      "source": [
        "print(\"Creating dataset...\")\n",
        "train_dataset = CellDataset(TRAIN_DIR, image_size=IMG_SIZE)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "print(f\"Train samples: {len(train_dataset)}\")\n",
        "\n",
        "print(\"\\nCreating model...\")\n",
        "model = ResNetUNet(num_classes=4)\n",
        "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "print(\"\\nTraining...\")\n",
        "# Run for more epochs\n",
        "EPOCHS = 30\n",
        "model = train_model_team(model, train_loader, EPOCHS, DEVICE, alpha=0.5, beta=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "e61d5623"
      },
      "outputs": [],
      "source": [
        "# Load the ground truth CSV\n",
        "ground_truth_path = BASE / \"train_ground_truth.csv\"\n",
        "ground_truth_df = pd.read_csv(str(ground_truth_path))\n",
        "ground_truth_df.set_index('image_id', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "3780a91a",
        "outputId": "9a6ba47b-94b9-4465-e228-e50bfeef5fb5"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'best_model.pth'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mGround truth DataFrame not loaded. Run the cell above first.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Load best model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m model.load_state_dict(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbest_model.pth\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Define the path to slide1.tif\u001b[39;00m\n\u001b[32m      9\u001b[39m slide1_path = TRAIN_DIR / \u001b[33m\"\u001b[39m\u001b[33mslide1.tif\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\serialization.py:1425\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args.keys():\n\u001b[32m   1423\u001b[39m     pickle_load_args[\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1425\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m   1426\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1427\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1428\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1429\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1430\u001b[39m         orig_position = opened_file.tell()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\serialization.py:751\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    749\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[32m    750\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m751\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    752\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    753\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\serialization.py:732\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'best_model.pth'"
          ]
        }
      ],
      "source": [
        "# Load the ground truth CSV (if not already loaded)\n",
        "if 'ground_truth_df' not in locals():\n",
        "    raise Exception(\"Ground truth DataFrame not loaded. Run the cell above first.\")\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "\n",
        "# Define the path to slide1.tif\n",
        "slide1_path = TRAIN_DIR / \"slide1.tif\"\n",
        "\n",
        "# Use the analyze_and_visualize_masks function\n",
        "analyze_and_visualize_masks(slide1_path, model, ground_truth_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "kLrcs7NTnq3m",
        "outputId": "368b3a91-782a-4ed5-f930-cd8f8018b4aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generating predictions...\n",
            "\n",
            "Predicting on 40 test images...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:03<00:00, 12.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "âœ… Submission saved: submission.csv\n",
            "Shape: (40, 5)\n",
            "\n",
            "Sample rows:\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"submission_df\",\n  \"rows\": 40,\n  \"fields\": [\n    {\n      \"column\": \"slide_num\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 1,\n        \"max\": 40,\n        \"num_unique_values\": 40,\n        \"samples\": [\n          20,\n          17,\n          16\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 40,\n        \"samples\": [\n          \"slide20\",\n          \"slide17\",\n          \"slide16\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Epithelial\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 40,\n        \"samples\": [\n          \"2 1846 6 2 1985 2 1 5168 2 1 5306 3 1 5443 5 1 5581 5 1 5720 2 3 6344 4 4 7058 2 4 7196 5 4 7335 5 5 8174 2\",\n          \"19 1581 4 19 1834 4 19 2087 5 19 2340 5 19 2593 5 5 2808 1 19 2846 5 1 3049 2 5 3061 3 19 3099 6 1 3300 5 5 3314 3 19 3351 7 43 3434 1 1 3552 12 19 3604 6 43 3686 2 46 3696 2 1 3804 14 19 3857 6 43 3939 2 46 3948 3 1 4057 14 19 4109 7 43 4192 3 46 4201 4 1 4308 16 19 4362 6 43 4445 3 46 4454 5 57 4485 2 1 4559 18 19 4615 4 43 4698 3 46 4707 5 1 4811 19 19 4866 5 43 4952 3 46 4960 5 1 5063 18 19 5118 2 19 5121 1 43 5205 3 46 5214 4 1 5316 16 19 5371 1 43 5458 3 46 5467 3 64 5540 1 1 5569 16 50 5740 1 65 5796 1 1 5822 16 50 5992 5 65 6048 4 1 6075 16 50 6243 8 65 6301 5 1 6328 17 15 6375 1 50 6495 10 65 6554 5 1 6581 17 4 6601 1 15 6628 1 50 6747 12 65 6808 5 1 6834 17 4 6853 3 15 6881 1 50 6999 13 65 7063 5 1 7087 17 4 7106 2 50 7252 13 65 7317 6 1 7340 17 4 7360 1 12 7384 1 50 7505 12 65 7571 6 1 7594 16 12 7635 4 50 7759 4 65 7825 6 1 7848 15 12 7887 5 50 8012 4 65 8078 6 1 8102 13 12 8140 6 65 8331 6 1 8355 14 12 8392 7 65 8585 5 1 8609 13 6 8628 1 12 8644 8 48 8775 2 65 8840 3 1 8862 13 6 8880 2 12 8897 8 48 9027 3 65 9094 2 1 9116 13 6 9133 2 12 9150 6 48 9279 4 65 9348 1 1 9370 12 6 9386 2 12 9403 2 48 9525 3 48 9531 5 67 9602 1 1 9624 11 48 9778 11 67 9855 2 1 9878 10 31 10003 7 48 10031 9 67 10108 3 1 10134 7 31 10234 1 31 10245 2 31 10254 11 48 10283 10 67 10361 3 1 10390 5 31 10485 5 31 10497 5 31 10507 11 48 10536 6 67 10614 4 1 10645 4 8 10661 3 31 10737 7 31 10749 7 31 10760 11 48 10788 7 67 10867 4 1 10899 4 1 10907 3 8 10913 4 31 10989 10 31 11001 9 31 11013 11 48 11039 8 67 11120 5 1 11152 13 8 11166 1 8 11168 1 31 11240 24 31 11266 11 48 11290 9 67 11373 5 1 11405 13 31 11492 37 48 11543 4 67 11626 5 1 11658 12 31 11744 37 48 11796 4 67 11879 5 1 11911 12 31 11996 38 48 12049 4 67 12132 5 1 12166 9 31 12246 41 48 12301 5 67 12385 4 1 12423 1 1 12425 1 31 12498 13 31 12515 19 31 12538 2 48 12554 5 67 12638 4 31 12749 14 31 12768 19 31 12791 4 48 12807 5 67 12891 4 31 13002 13 31 13022 5 31 13030 10 31 13045 4 48 13060 6 67 13144 4 31 13254 14 31 13276 4 31 13284 9 31 13298 5 48 13313 6 67 13397 4 31 13507 13 31 13536 10 31 13553 3 48 13566 6 67 13651 3 31 13759 13 31 13789 10 31 13807 2 48 13819 6 67 13904 3 31 14011 13 31 14042 10 48 14072 5 67 14158 1 31 14264 13 31 14295 10 48 14325 5 67 14411 1 31 14516 14 31 14547 12 48 14579 4 31 14769 13 31 14800 12 48 14832 4 31 15022 14 31 15053 13 48 15085 4 31 15275 13 31 15301 1 31 15306 14 48 15338 4 31 15529 15 31 15545 12 31 15559 14 48 15592 4 31 15782 14 31 15797 29 48 15845 4 31 16035 43 48 16098 4 31 16289 41 48 16351 4 31 16542 39 48 16605 3 31 16795 39 48 16859 1 31 17048 38 31 17301 38 22 17535 8 31 17555 36 22 17787 11 31 17809 35 22 18038 14 31 18063 31 22 18290 16 31 18317 30 22 18542 17 31 18573 21 31 18598 1 22 18794 19 31 18828 19 22 19046 8 31 19093 6 22 19299 8 31 19347 4 22 19551 7 22 19804 7 30 19830 3 22 20056 6 30 20083 4 22 20309 6 30 20336 6 22 20562 5 30 20589 7 22 20815 5 30 20842 9 30 21095 11 30 21348 12 21 21572 2 30 21601 12 21 21824 4 30 21852 15 21 22077 4 30 22104 16 21 22330 4 30 22357 16 21 22582 5 30 22610 2 30 22613 13 21 22835 5 30 22868 12 21 23088 4 30 23123 10 49 23182 1 21 23342 4 30 23377 9 21 23595 3 30 23634 6 21 23848 4 30 23887 6 17 24092 4 21 24101 4 30 24140 6 17 24344 5 21 24354 4 30 24394 5 17 24597 5 21 24608 4 30 24647 5 59 24732 1 17 24851 4 21 24861 3 30 24900 5 17 25106 2 21 25114 4 30 25154 3 47 25208 4 60 25238 2 21 25368 3 30 25407 3 47 25459 7 21 25621 4 30 25660 2 47 25712 9 21 25875 3 30 25913 2 41 25942 1 47 25965 10 21 26128 5 41 26194 3 47 26218 10 21 26382 4 41 26446 5 47 26471 11 21 26635 5 41 26699 5 47 26723 11 21 26889 4 41 26952 5 47 26976 10 21 27142 4 41 27205 5 47 27229 8 21 27396 3 41 27459 3 47 27482 7 47 27735 5 47 27987 5 47 28239 6 47 28493 5 47 28505 3 47 28747 4 47 28757 5 28 28952 2 47 29000 5 47 29009 6 26 29180 1 28 29205 3 47 29254 5 47 29261 7 47 29271 2 28 29458 3 47 29507 19 28 29711 4 39 29726 1 47 29760 19 28 29965 4 39 29979 1 47 30013 20 28 30217 5 39 30231 2 47 30266 20 28 30467 8 39 30484 2 47 30521 18 28 30720 8 39 30738 1 47 30776 16 28 30973 8 47 31030 15 28 31226 8 47 31284 14 28 31479 8 47 31539 12 28 31732 9 47 31794 9 28 31986 9 47 32050 4 28 32240 8 47 32303 2 28 32494 7 47 32556 3 28 32747 7 40 32762 2 47 32809 2 28 33000 7 40 33016 2 44 33048 6 47 33062 1 28 33249 10 40 33269 2 44 33292 2 44 33299 10 28 33500 8 44 33544 5 44 33551 14 28 33745 3 28 33753 8 44 33797 21 28 33997 6 28 34005 8 42 34039 4 44 34049 22 28 34249 16 42 34292 4 44 34302 22 28 34502 15 42 34544 5 44 34555 21 28 34754 16 42 34797 6 44 34808 21 58 34846 5 28 35006 8 28 35017 5 35 35031 1 42 35050 6 44 35062 19 28 35258 9 28 35271 4 36 35285 1 42 35303 6 44 35315 18 56 35350 1 28 35511 7 28 35525 2 36 35538 1 42 35557 5 44 35570 14 28 35764 7 28 35778 2 36 35791 1 42 35810 4 44 35823 12 28 36018 4 44 36077 9 28 36272 3 44 36330 8 53 36355 2 44 36583 6 53 36607 3 27 36774 2 44 36836 6 53 36859 5 27 37026 5 44 37089 6 53 37111 5 27 37279 6 44 37342 6 53 37363 6 27 37531 8 44 37596 4 53 37616 5 27 37784 9 44 37850 3 53 37869 5 27 38036 10 53 38122 3 27 38289 10 27 38310 1 53 38375 3 27 38542 10 27 38560 8 27 38795 10 27 38813 8 27 39049 9 27 39066 9 27 39302 9 27 39319 9 27 39557 7 27 39572 9 27 39813 4 27 39825 8 63 39935 2 27 40067 3 27 40078 7 63 40189 3 27 40321 2 27 40331 4 63 40442 4 27 40574 12 63 40695 4 27 40832 6 63 40948 5 27 41088 1 63 41201 5 51 41408 1 63 41454 5 63 41707 5 63 41960 5 63 42213 5 63 42465 6 63 42718 6 63 42971 6 63 43223 7 63 43476 7 63 43727 8 63 43980 8 33 44137 1 63 44232 7 63 44485 6 34 44644 2 63 44738 5 34 44898 1 63 44990 5 34 45151 1 61 45231 3 63 45244 2 61 45484 5 61 45737 5 9 45827 4 61 45990 5 9 46080 5 13 46090 7 61 46243 7 9 46333 5 13 46342 9 61 46496 7 9 46586 5 13 46594 10 52 46721 1 61 46749 8 13 46847 10 52 46974 1 61 47001 8 13 47100 11 52 47227 1 61 47253 8 3 47330 1 13 47353 11 61 47505 6 3 47582 2 13 47606 11 45 47717 3 61 47757 6 3 47833 4 13 47859 11 38 47961 3 45 47969 4 61 48009 5 3 48086 2 13 48113 10 38 48211 6 45 48222 5 61 48262 3 3 48337 3 13 48367 9 38 48462 7 45 48474 6 3 48590 2 13 48620 9 38 48714 7 45 48729 5 3 48842 2 13 48873 9 38 48965 9 45 48982 6 3 49095 2 13 49127 8 38 49211 16 45 49238 4 3 49348 2 13 49380 8 38 49462 18 45 49491 5 3 49600 3 13 49634 7 38 49713 14 45 49745 5 3 49853 3 13 49887 7 38 49965 10 38 49977 3 45 49999 3 3 50106 3 13 50140 6 38 50217 9 38 50230 1 3 50360 1 13 50393 6 38 50470 9 3 50613 1 13 50645 6 38 50723 8 13 50898 6 38 50976 8 13 51151 6 38 51229 6 13 51404 5 38 51482 6 13 51656 6 38 51736 4 13 51909 5 2 52126 1 13 52162 4 2 52379 1 13 52415 4 37 52493 1 2 52631 3 13 52668 4 37 52746 1 2 52884 4 13 52921 4 37 52999 1 2 53137 5 13 53174 4 37 53251 3 2 53391 4 13 53427 3 37 53505 1 2 53644 4 13 53681 2 37 53758 2 2 53897 6 13 53934 2 37 54011 1 2 54151 6 2 54404 7 2 54657 8 2 54911 6 2 55165 5 2 55418 4 10 55445 6 2 55672 3 10 55697 7 55 55838 1 10 55951 5 55 56091 3 10 56205 3 55 56344 3 55 56597 3 55 56850 3 55 57103 4 55 57358 1 66 58174 8 66 58426 12 66 58679 13 66 58932 14 66 59184 13 66 59437 12 66 59690 12 66 59943 13 66 60196 14 66 60449 14 66 60702 14 66 60955 14 66 61210 11 24 61306 2 66 61464 10 66 61719 8 66 61972 8 54 62175 4 54 62181 4 66 62225 8 54 62426 13 66 62478 8 54 62676 17 66 62731 8 54 62928 19 66 62983 9 54 63180 20 54 63213 6 66 63229 2 66 63235 10 54 63433 21 54 63464 9 66 63482 4 66 63487 11 54 63686 22 54 63715 12 66 63734 16 54 63938 24 54 63967 14 66 63987 16 54 64191 25 54 64219 15 66 64240 15 54 64443 45 66 64493 14 54 64695 6 54 64705 36 66 64746 12 54 64948 6 54 64959 35 66 65000 11 54 65201 6 54 65215 32 66 65253 10 54 65454 6 54 65469 31 66 65507 8 54 65707 6 54 65722 30 66 65762 6 54 65960 5 54 65975 29 66 66017 4 54 66213 4 54 66228 5 54 66239 18 66 66271 4 54 66466 4 54 66481 5 54 66492 11 54 66505 3 66 66526 1 29 66630 1 32 66642 2 54 66720 2 54 66733 6 54 66745 11 54 66759 2 66 66779 1 29 66883 1 32 66895 2 54 66972 3 54 66987 5 54 66998 11 54 67012 1 32 67148 3 54 67225 3 54 67240 5 54 67252 9 54 67478 3 54 67495 3 54 67506 7 62 67517 2 54 67730 4 62 67769 3 54 67982 5 62 68022 3 54 68235 5 62 68276 2 14 68358 2 25 68397 1 54 68487 6 62 68529 2 14 68611 2 18 68619 2 25 68649 3 54 68740 6 62 68782 2 14 68864 2 18 68872 2 25 68902 2 54 68994 4 62 69035 2 14 69117 3 18 69125 4 25 69154 3 54 69247 4 62 69288 2 14 69370 4 18 69378 5 25 69407 2 54 69500 3 62 69541 3 14 69623 4 18 69632 4 25 69660 2 54 69753 3 62 69794 8 14 69877 4 18 69886 2 25 69911 4 54 70006 3 62 70047 10 11 70121 1 14 70130 4 20 70145 5 25 70164 4 54 70259 3 62 70300 14 14 70383 4 20 70397 7 25 70416 4 54 70512 3 62 70553 16 14 70637 4 20 70649 8 25 70668 4 54 70765 3 62 70806 17 14 70890 6 20 70902 6 25 70921 3 54 71018 3 62 71059 18 14 71145 5 20 71156 5 25 71175 1 54 71271 3 62 71312 18 14 71400 4 20 71407 8 54 71524 3 62 71565 18 14 71654 4 20 71661 7 23 71675 1 54 71777 3 62 71818 19 14 71907 3 20 71916 1 23 71927 2 54 72030 4 62 72071 16 62 72088 4 14 72160 3 23 72180 2 54 72283 5 62 72323 24 14 72412 5 54 72536 5 62 72576 25 14 72664 6 54 72789 5 62 72829 26 14 72917 7 54 73042 5 62 73082 26 14 73170 8 54 73295 5 62 73334 28 14 73424 7 14 73438 4 54 73548 5 62 73588 27 7 73652 2 14 73678 7 14 73689 9 54 73801 5 62 73841 27 7 73904 4 14 73931 21 54 74054 5 62 74094 27 7 74157 4 14 74185 21 54 74307 6 62 74347 27 7 74410 4 14 74441 19 54 74561 7 62 74600 26 7 74663 5 14 74695 21 54 74815 7 62 74852 27 7 74916 5 14 74949 22 54 75069 8 62 75104 28 7 75169 6 14 75202 23 54 75322 8 62 75356 28 7 75423 7 14 75455 24 54 75575 11 62 75609 24 7 75677 6 14 75708 25 54 75829 11 62 75861 25 14 75961 25 54 76083 11 62 76113 25 14 76213 26 54 76337 10 62 76366 25 16 76462 2 14 76466 27 54 76592 9 62 76617 23 62 76641 1 62 76643 2 16 76715 2 14 76720 26 54 76845 9 62 76869 20 16 76967 3 14 76975 23 54 77100 9 62 77117 16 62 77139 1 16 77220 3 14 77228 23 54 77354 2 54 77359 3 62 77370 16 16 77471 3 14 77482 11 14 77495 9 62 77623 14 16 77725 2 14 77737 7 14 77749 8 62 77877 11 14 78003 6 62 78131 7 14 78256 6 62 78385 6 14 78510 5 62 78638 5 14 78763 4 62 78891 5 62 79143 4 62 79397 3\",\n          \"12 5804 1 12 6204 4 12 6605 5 12 7006 6 19 7179 11 12 7407 7 19 7579 13 12 7808 7 19 7979 15 12 8209 7 19 8378 18 12 8610 7 19 8778 19 12 9011 5 19 9179 20 12 9412 5 19 9579 21 12 9813 5 18 9965 3 19 9979 22 12 10214 2 18 10363 8 19 10380 22 18 10763 9 19 10781 22 18 11164 10 19 11182 22 18 11564 12 19 11583 21 18 11961 16 19 11985 20 18 12362 16 19 12387 18 18 12763 17 19 12793 12 18 13164 17 19 13194 12 18 13569 13 19 13598 7 18 13971 11 19 14000 5 18 14373 10 19 14402 2 18 14776 7 18 15179 3 9 22602 3 9 23002 6 9 23403 6 20 23639 3 9 23803 8 20 24035 9 9 24204 8 20 24434 13 9 24605 10 20 24834 16 9 25006 10 20 25234 17 9 25407 10 20 25635 18 9 25808 12 20 26036 19 9 26209 12 20 26437 20 9 26610 12 20 26838 20 9 27012 11 20 27239 21 9 27413 11 20 27641 20 9 27815 12 20 28043 20 9 28216 13 20 28445 19 9 28617 13 20 28847 17 9 29020 11 20 29249 15 9 29421 11 20 29652 12 9 29823 10 9 30224 10 9 30626 9 9 31029 6 9 31432 1 24 31668 8 24 32068 11 24 32468 13 24 32868 14 24 33269 14 24 33670 14 24 34071 14 24 34472 14 24 34875 12 24 35276 12 24 35680 9 24 36084 6 24 36485 6 24 36888 4 24 37292 1 15 51207 9 15 51607 11 15 52007 13 15 52407 15 15 52808 15 15 53208 16 15 53608 18 15 54009 18 15 54410 18 15 54812 17 15 55213 17 15 55615 15 15 56016 15 15 56417 15 15 56820 12 15 57222 11 15 57623 10 15 58028 5 15 58430 3 7 59081 3 7 59480 6 7 59880 8 23 60136 7 7 60280 11 23 60536 9 7 60680 12 23 60936 11 7 61081 13 23 61336 13 7 61482 14 23 61737 14 7 61882 15 23 62137 15 7 62283 16 14 62403 6 23 62538 15 7 62684 16 14 62803 7 23 62939 16 7 63085 17 14 63203 8 23 63339 17 7 63486 18 14 63604 8 23 63740 16 7 63887 18 14 64004 9 23 64141 17 7 64288 18 14 64405 9 23 64542 16 7 64689 19 14 64806 9 23 64943 16 7 65090 19 14 65207 9 23 65344 15 7 65492 18 14 65609 4 23 65747 13 7 65893 18 14 66011 2 23 66148 13 7 66294 18 14 66413 1 23 66550 12 7 66696 17 23 66953 9 7 67098 16 17 67299 2 23 67354 9 7 67499 16 17 67699 3 23 67758 5 7 67902 13 17 68097 6 7 68304 12 17 68499 5 7 68706 11 7 69109 7 7 69510 7 7 69913 2 16 88123 5 16 88524 6 16 88925 7 16 89327 8 16 89728 9 16 90129 9 16 90530 9 16 90932 8 16 91334 8 16 91737 7 16 92139 6 16 92542 4 16 92944 1 16 92946 1 1 94279 7 1 94677 10 1 95078 10 1 95476 13 1 95876 14 1 96277 14 1 96677 15 1 97078 15 1 97479 15 1 97880 15 1 98281 15 1 98682 13 1 99083 12 1 99484 12 1 99887 8 1 100289 5 1 100691 3 11 105224 4 3 105539 7 11 105623 9 3 105940 9 11 106023 10 3 106341 11 6 106388 4 11 106423 12 3 106740 15 6 106787 7 11 106822 16 3 107141 15 6 107188 7 11 107223 16 3 107542 16 6 107589 8 11 107624 18 3 107943 17 6 107989 9 10 108013 1 11 108025 20 3 108344 17 6 108390 9 11 108426 20 3 108747 15 6 108790 11 11 108827 21 3 109148 16 6 109191 11 11 109228 22 3 109549 16 6 109592 12 11 109629 22 3 109951 15 6 109993 12 11 110030 23 3 110353 14 6 110394 12 11 110431 23 3 110754 14 6 110795 13 11 110832 23 3 111156 12 6 111198 11 11 111233 23 3 111557 12 6 111599 11 11 111634 23 3 111959 11 6 112002 9 11 112035 23 22 112261 5 3 112361 9 6 112406 7 11 112436 23 22 112660 11 3 112764 6 6 112807 6 11 112837 23 22 113061 13 6 113211 2 11 113238 22 22 113462 15 11 113640 21 22 113863 16 11 114041 20 22 114263 18 11 114443 19 22 114664 18 11 114845 17 22 115065 19 11 115246 17 22 115466 20 11 115649 13 22 115868 19 11 116051 9 22 116269 20 22 116670 20 22 117073 18 22 117474 18 22 117876 16 22 118278 15 22 118680 14 22 119084 10 22 119487 5 22 119890 1 25 123098 3 25 123103 1 25 123497 9 25 123896 11 25 124296 13 25 124697 13 25 125098 13 25 125500 13 13 125714 3 25 125901 13 13 126114 4 25 126302 13 13 126515 6 25 126703 12 13 126916 6 25 127104 4 25 127113 3 13 127317 6 25 127505 4 25 127514 3 13 127718 6 25 127906 4 13 128120 5 25 128308 1 13 128521 5 5 131249 4 5 131651 3 5 132050 8 5 132449 11 21 132710 5 5 132850 12 21 133111 6 5 133251 12 21 133511 8 5 133651 14 21 133912 9 5 134052 14 21 134313 9 5 134452 16 21 134713 10 5 134853 16 21 135114 11 5 135255 15 21 135516 9 5 135656 15 21 135918 8 5 136058 13 21 136319 8 5 136459 13 5 136862 11 5 137263 10 5 137666 6 8 142491 3 8 142890 5 8 142896 1 8 143286 13 8 143686 15 8 144087 16 8 144488 20 8 144889 21 8 145290 21 8 145692 22 8 146093 22 8 146495 21 8 146897 20 8 147299 19 8 147701 17 8 148104 14 8 148507 12 8 148910 8 8 149311 7 2 149632 2 8 149714 5 2 150031 6 2 150432 7 2 150832 10 2 151233 11 2 151634 11 2 152033 14 2 152434 14 2 152835 14 2 153236 15 2 153636 16 2 154037 16 2 154437 17 2 154838 17 2 155239 17 2 155639 18 2 156040 18 2 156441 18 2 156842 17 2 157244 16 2 157646 15 4 157692 10 2 158047 15 4 158092 12 2 158449 14 4 158492 14 2 158850 13 4 158893 15 2 159252 12 4 159293 16 2 159654 11 4 159694 16 2 160057 8 4 160095 17 2 160459 7 4 160496 17 4 160897 17 4 161298 17 4 161699 17 4 162101 15 4 162502 15 4 162904 14 4 163308 11 4 163709 11 4 164111 9 4 164514 7 4 164915 5\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lymphocyte\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 35,\n        \"samples\": [\n          \"4 30889 4 4 32860 7 4 34832 10 4 36806 10 4 38780 10 4 40754 9 4 42728 8 4 44705 4 6 740228 2 6 742197 10 6 744170 12 6 746144 12 6 748118 12 6 750092 11 6 752066 9 6 754040 8 6 756015 2 1 762367 4 1 764340 5 1 766313 6 1 768285 9 1 770258 11 1 772231 13 1 774205 13 1 776179 13 1 778153 13 1 780127 12 1 782102 10 1 784077 8 1 786056 1 5 960831 9 5 962803 14 5 964777 15 5 966750 17 5 968724 17 5 970699 15 5 972673 15 5 974648 13 5 976625 10 5 978601 3 2 1072776 5 2 1074747 10 2 1076720 12 2 1078693 14 2 1080666 17 2 1082639 19 2 1084612 20 2 1086587 19 2 1088561 19 2 1090537 17 2 1092512 15 2 1094487 12 2 1096462 10 2 1098438 6 3 1347481 7 3 1349454 9 3 1351426 12 3 1353399 13 3 1355372 13 3 1357346 13 3 1359319 14 3 1361292 15 3 1363266 15 3 1365240 15 3 1367214 15 3 1369188 15 3 1371164 12 3 1373140 6\",\n          \"2 546 10 2 799 13 2 1052 14 2 1305 14 2 1557 16 2 1810 15 2 2063 16 5 2268 2 2 2316 16 5 2521 2 2 2568 16 2 2821 16 2 3074 16 2 3327 15 2 3580 15 2 3833 14 2 4087 13 2 4340 12 2 4593 9 2 4847 6 2 5100 5 2 5355 1 4 20136 3 4 20388 3 4 20631 14 4 20883 15 4 21135 16 4 21388 16 4 21640 18 4 21893 18 4 22146 19 4 22399 19 4 22652 20 4 22906 18 4 23159 18 4 23413 17 4 23667 15 4 23921 13 4 24175 11 4 24428 10 4 24683 6 3 39344 4 3 39593 10 3 39843 15 3 40094 18 3 40346 20 3 40598 22 3 40851 23 3 41103 25 3 41355 26 3 41607 27 3 41860 28 3 42113 28 3 42366 28 3 42619 28 3 42872 28 3 43125 28 3 43378 27 3 43631 27 3 43885 25 3 44138 25 3 44392 23 3 44646 21 3 44899 20 3 45154 18 3 45407 17 3 45661 14 3 45915 12 3 46171 7 1 76418 7 1 76671 8 1 76924 8 1 77177 8 1 77429 9 1 77683 1 1 77685 6\",\n          \"3 1617 4 3 1837 8 3 2058 7 3 2279 6 3 2501 3 5 5723 5 5 5942 8 5 6162 10 5 6382 11 5 6603 11 5 6825 9 5 7046 9 5 7267 9 5 7489 7 5 7710 7 5 7931 6 5 8153 4 4 10503 2 4 10721 8 4 10941 10 4 11160 13 4 11381 14 4 11602 14 4 11823 15 4 12044 15 4 12265 15 4 12486 16 4 12707 16 4 12928 15 4 13149 15 4 13371 14 4 13592 13 4 13813 12 4 14035 11 4 14257 8 4 14479 6 1 17520 4 1 17739 9 1 17959 11 1 18179 13 1 18399 15 1 18620 15 1 18841 16 1 19061 17 1 19283 16 1 19504 16 1 19725 16 1 19947 15 1 20168 14 1 20390 12 1 20612 10 1 20835 5 2 21944 4 2 22164 6 2 22384 7 2 22605 7 2 22825 8 2 23046 9 2 23267 9 2 23488 8 2 23709 5 2 23931 3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Neutrophil\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 28,\n        \"samples\": [\n          \"3 3067 1 3 3238 1 3 3408 2 3 3579 2 3 3750 2 3 3921 2 3 4092 2 3 4264 1 3 4435 1 2 31773 1 2 31941 6 2 32108 11 2 32278 13 2 32449 15 2 32620 16 2 32791 17 2 32962 17 2 33133 17 2 33304 17 2 33475 17 2 33647 16 2 33818 16 2 33989 15 2 34161 14 2 34333 13 2 34505 11 2 34676 10 2 34849 7 2 35022 3 1 43023 4 1 43194 5 1 43363 7 1 43534 7 1 43705 8 1 43876 8 1 44047 8 1 44219 8 1 44391 6 1 44563 5\",\n          \"3 158951 2 4 170951 2 4 172451 3 2 1824447 2 2 1825946 3 2 1827445 4 2 1828944 6 2 1830443 7 2 1831943 7 2 1833443 7 2 1834942 7 2 1836442 7 2 1837942 7 2 1839442 7 2 1840943 6 2 1842443 6 2 1843943 6 2 1845443 6 2 1846943 6 1 1848425 3 2 1848444 5 1 1849924 6 2 1849944 5 1 1851423 8 1 1852923 8 1 1854423 8 1 1855923 8 1 1857425 7 1 1858926 6 1 1860427 5 1 1861927 4 1 1863428 3\",\n          \"10 7583 7 10 7789 8 10 7994 9 10 8200 14 10 8406 15 10 8612 15 10 8818 14 10 9024 14 10 9231 12 10 9438 10 10 9646 6 9 14783 6 9 14988 9 9 15192 12 9 15397 13 9 15601 16 9 15806 18 9 16012 18 9 16217 19 9 16423 20 9 16628 21 9 16833 23 9 17039 23 9 17245 23 9 17451 23 9 17658 22 9 17864 22 9 18070 22 9 18277 21 9 18484 19 9 18690 18 9 18897 17 9 19104 15 9 19311 13 9 19518 11 9 19728 4 8 20119 5 8 20323 9 8 20527 12 8 20732 14 8 20937 16 8 21141 19 8 21347 19 8 21551 22 8 21757 22 8 21963 22 8 22168 23 8 22374 24 8 22580 24 8 22786 24 8 22992 24 8 23198 24 8 23404 24 8 23611 22 8 23817 22 8 24023 22 8 24229 22 8 24435 22 8 24642 20 8 24848 20 8 25055 19 8 25262 17 7 25445 5 8 25469 14 7 25652 8 8 25678 10 7 25858 9 8 25887 4 7 26064 11 7 26270 11 7 26476 12 7 26675 2 7 26682 13 7 26875 8 7 26888 13 7 27080 9 7 27094 13 7 27285 10 7 27300 13 7 27491 10 7 27506 13 7 27697 10 7 27712 13 7 27903 11 7 27918 13 7 28109 28 7 28316 27 7 28522 27 7 28728 26 7 28935 25 7 29141 24 7 29348 22 7 29555 20 7 29763 15 7 29971 11 6 31833 5 6 32034 13 6 32236 18 6 32440 20 6 32646 21 6 32851 22 6 33056 23 6 33262 23 6 33467 24 6 33673 23 6 33879 23 6 34085 23 6 34290 24 6 34496 23 6 34702 23 6 34907 24 6 35113 24 6 35319 23 6 35525 23 6 35730 23 6 35936 23 6 36142 21 6 36348 20 6 36555 16 6 36761 13 6 36968 9 6 37176 3 4 43920 5 4 44122 11 4 44326 14 4 44531 16 4 44736 19 4 44941 8 4 44952 9 4 45146 8 4 45159 9 4 45351 9 4 45365 9 4 45557 9 4 45572 8 4 45762 10 4 45778 8 4 45968 10 4 45985 7 4 46174 10 4 46191 7 4 46380 10 4 46397 7 4 46586 10 4 46604 6 4 46792 10 4 46810 6 4 46998 11 4 47015 7 4 47204 11 4 47221 7 4 47410 11 4 47426 8 4 47617 11 4 47631 8 4 47823 13 4 47837 8 4 48031 19 4 48238 17 4 48446 13 4 48654 9 5 48889 4 5 49093 8 5 49298 9 5 49503 10 5 49708 12 2 49867 3 5 49914 12 1 50070 1 2 50075 1 5 50119 14 1 50275 2 2 50281 1 5 50325 15 1 50480 3 1 50488 1 5 50531 17 1 50686 3 1 50694 1 3 50701 3 5 50736 18 1 50891 4 1 50900 1 3 50904 6 5 50942 19 1 51097 5 1 51106 1 3 51113 4 5 51147 21 1 51303 5 1 51312 1 3 51320 3 5 51353 21 1 51509 10 3 51528 1 5 51559 21 1 51715 11 5 51765 21 1 51921 11 5 51971 21 1 52128 10 5 52177 21 1 52334 10 5 52383 21 1 52541 10 5 52589 21 1 52749 8 5 52795 20 1 52956 6 5 53002 19 1 53164 4 5 53209 17 5 53416 16 5 53623 14 5 53831 10\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Macrophage\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 33,\n        \"samples\": [\n          \"10 1743 17 10 1963 21 10 2184 23 10 2406 25 1 2525 4 10 2628 26 1 2746 6 10 2851 26 1 2968 7 10 3072 27 1 3187 10 10 3295 27 1 3409 10 10 3517 27 1 3631 9 10 3738 28 1 3853 8 10 3961 27 1 4075 6 10 4183 28 1 4298 5 10 4406 27 1 4520 5 10 4628 27 1 4744 2 10 4852 24 1 4967 1 10 5074 23 3 5191 2 10 5296 23 3 5413 9 10 5518 23 3 5637 4 10 5740 22 10 5962 22 10 6184 22 10 6407 21 10 6629 21 10 6852 20 10 7074 20 10 7298 18 10 7520 18 10 7742 18 10 7965 16 10 8188 13 10 8412 10 10 8635 9 10 8858 5 8 9484 5 8 9701 11 8 9921 14 8 10141 17 8 10360 21 8 10578 25 8 10800 25 8 11022 25 8 11243 26 8 11465 26 8 11687 26 8 11909 25 8 12132 7 8 12141 13 8 12356 2 8 12364 4 9 13714 1 9 13935 3 9 14156 4 9 14377 6 9 14598 7 9 14819 8 9 15040 9 9 15262 8 9 15484 8 9 15706 9 9 15928 8 9 16152 5 7 18108 1 7 18330 3 4 20082 3 4 20303 4 4 20523 6 4 20742 10 4 20963 12 4 21184 14 4 21405 15 4 21626 16 4 21849 5 4 21855 9 4 22071 5 4 22077 9 4 22294 14 4 22516 14 4 22738 14 4 22960 15 4 23182 14 4 23404 14 4 23626 14 4 23849 11 5 25181 3 5 25402 5 5 25624 7 5 25846 7 5 26069 6 5 26292 5 5 26515 3 2 33607 2 2 33828 3 2 34050 4 2 34272 5 2 34494 6 2 34716 7 2 34938 7 6 34950 5 2 35160 7 6 35171 6 2 35383 7 6 35393 6 2 35605 7 6 35615 6 2 35827 7 6 35838 3 2 36049 7 2 36271 6 2 36494 5 2 36716 4 2 36939 3 2 37162 2\",\n          \"4 48 7 4 179 18 4 204 9 4 317 36 4 456 36 3 586 4 4 600 31 8 644 3 3 725 5 4 743 25 8 781 7 3 864 5 4 883 22 8 917 11 3 1003 5 4 1023 20 8 1055 14 3 1141 5 4 1162 18 8 1193 15 3 1279 5 4 1301 17 8 1334 14 6 1438 2 4 1441 14 8 1475 13 6 1577 2 4 1583 10 8 1617 10 4 1723 8 8 1757 9 4 1864 6 8 1898 7 4 2003 6 8 2036 8 4 2142 6 8 2176 7 4 2281 1 8 2316 6 8 2456 4 1 3202 5 1 3340 6 1 3479 7 1 3618 8 1 3757 9 1 3897 8 1 4037 9 1 4179 6 5 4215 3 1 4320 5 5 4352 8 7 4367 4 1 4460 5 5 4490 9 7 4505 5 1 4602 3 5 4629 8 7 4645 4 2 4732 2 5 4769 7 7 4783 6 2 4870 4 5 4910 8 7 4922 6 2 5010 3 5 5049 10 7 5061 6 5 5189 10 7 5200 5 5 5328 10 7 5340 2 5 5468 8 9 5544 1 5 5607 8 9 5680 6 5 5747 4 9 5816 8 13 5829 1 5 5886 3 9 5954 7 13 5968 2 5 6025 3 13 6107 5 5 6165 1 13 6246 6 13 6388 3 13 6528 1 10 6796 2 11 7497 1 11 7634 7 11 7773 8 11 7912 8 12 8468 1\",\n          \"15 10650 2 15 10998 5 15 11346 12 15 11383 2 15 11657 4 15 11694 14 15 11731 2 15 12004 5 15 12042 16 15 12079 2 15 12349 11 15 12368 2 19 12381 2 15 12390 18 15 12426 5 15 12455 4 15 12697 11 15 12716 1 19 12729 2 15 12738 19 15 12774 5 15 12801 6 15 13044 24 15 13086 1 15 13088 20 15 13121 8 15 13147 13 15 13391 24 15 13434 1 15 13436 20 15 13469 8 15 13495 15 15 13738 27 15 13782 1 15 13784 24 15 13816 10 15 13841 19 15 14086 27 15 14130 1 15 14132 27 15 14162 12 15 14188 20 15 14434 28 15 14478 1 15 14480 43 15 14531 27 15 14781 30 15 14826 1 15 14828 44 15 14878 29 15 15128 32 15 15176 44 15 15226 30 15 15475 35 15 15524 45 15 15572 33 15 15823 36 15 15872 45 15 15920 34 15 16170 3 15 16174 36 15 16220 1 15 16222 40 15 16268 35 15 16518 41 15 16568 1 15 16570 40 15 16616 36 15 16865 4 15 16870 2 15 16877 1 15 16879 28 15 16916 41 15 16964 20 15 16985 17 15 17213 8 15 17225 31 15 17264 41 15 17312 39 15 17559 6 15 17575 79 15 17658 18 15 17686 14 15 17908 5 15 17923 79 15 18006 18 15 18034 15 15 18255 6 15 18271 1 15 18273 98 15 18384 14 15 18603 6 15 18619 100 15 18732 15 15 18948 10 15 18967 1 15 18969 98 15 19080 15 15 19295 11 15 19315 1 15 19317 98 15 19428 16 15 19642 14 15 19663 1 15 19665 98 15 19776 17 15 19989 17 15 20011 100 15 20124 18 15 20337 122 15 20470 1 15 20472 19 15 20683 124 15 20818 1 15 20820 19 15 21031 125 15 21166 1 15 21168 20 15 21379 126 15 21514 1 15 21516 20 15 21727 126 15 21862 22 15 22078 126 15 22210 23 15 22427 125 15 22558 24 15 22777 125 15 22904 1 15 22906 24 15 23125 153 15 23474 13 15 23489 137 15 23822 11 15 23839 136 15 24170 11 15 24187 136 15 24518 10 15 24535 136 15 24866 10 15 24883 136 15 25214 10 15 25231 136 15 25562 10 15 25579 135 15 25909 11 15 25927 1 15 25929 134 15 26257 11 15 26275 136 15 26605 11 15 26623 1 15 26625 135 15 26953 11 15 26971 137 15 27301 11 15 27319 79 15 27399 57 15 27649 10 15 27667 78 15 27746 22 15 27773 31 15 27998 8 15 28013 1 15 28015 76 15 28094 21 15 28123 29 15 28346 3 15 28350 1 15 28352 1 15 28361 77 15 28442 21 15 28472 28 15 28709 76 15 28789 22 15 28820 28 15 29055 78 15 29137 22 15 29170 26 15 29401 80 15 29485 22 15 29518 26 15 29748 80 15 29833 23 15 29866 26 15 30085 3 15 30096 81 15 30181 23 15 30214 26 15 30431 10 15 30442 83 15 30528 25 15 30562 26 15 30779 94 15 30876 25 15 30910 26 12 31114 1 15 31128 93 15 31224 25 15 31258 10 15 31269 15 12 31460 4 15 31476 93 15 31572 26 15 31606 26 12 31808 6 15 31825 93 15 31920 26 15 31954 26 12 32155 8 12 32165 1 15 32174 120 15 32302 25 12 32502 13 15 32522 120 15 32650 24 12 32850 13 15 32870 121 15 32998 24 12 33198 13 15 33218 121 15 33346 24 12 33546 10 12 33557 1 15 33566 122 15 33694 24 12 33892 12 12 33905 1 15 33913 124 15 34040 26 12 34238 13 15 34262 14 15 34277 118 15 34396 19 12 34587 13 15 34610 14 15 34625 138 10 34919 1 12 34932 14 15 34958 3 15 34962 1 15 34964 7 15 34973 1 15 34975 62 15 35038 1 15 35040 72 10 35267 2 12 35279 15 15 35306 3 15 35310 1 15 35312 8 15 35321 66 15 35388 72 10 35613 5 12 35626 14 15 35649 7 15 35663 68 15 35732 1 15 35734 1 15 35736 11 15 35749 59 10 35961 5 12 35974 13 15 35997 7 15 36012 69 15 36082 1 15 36084 11 15 36098 58 12 36323 11 15 36345 7 15 36360 56 15 36417 1 15 36419 3 15 36428 1 15 36430 1 15 36432 10 15 36446 60 12 36672 10 15 36693 6 15 36708 56 15 36765 1 15 36778 12 15 36794 60 12 37020 8 15 37042 5 15 37056 56 15 37126 11 15 37141 63 12 37369 5 15 37392 1 15 37405 53 15 37474 11 15 37488 65 12 37717 5 15 37753 55 15 37822 11 15 37834 67 12 38066 4 15 38100 54 15 38170 11 15 38182 3 15 38189 61 12 38414 3 15 38449 55 15 38518 14 15 38538 60 15 38797 54 15 38862 1 15 38864 11 15 38876 1 15 38888 60 15 39145 54 15 39210 12 15 39223 2 15 39238 58 15 39493 55 15 39558 5 15 39588 56 15 39841 55 15 39904 8 15 39936 57 15 40189 55 15 40254 4 15 40284 57 15 40537 31 15 40569 1 15 40571 23 15 40601 5 15 40630 1 15 40632 53 15 40687 2 15 40886 32 15 40919 6 15 40933 11 15 40949 5 15 40978 53 15 41235 11 15 41248 18 15 41267 4 15 41283 11 15 41296 3 15 41326 53 15 41583 11 15 41598 4 15 41606 10 15 41634 11 15 41674 52 15 41933 9 15 41957 6 15 41985 5 15 42020 1 15 42022 52 15 42281 9 15 42305 6 15 42368 1 15 42370 52 15 42631 12 15 42655 2 15 42716 54 15 42979 12 15 43003 2 15 43064 54 15 43331 7 15 43409 56 15 43679 7 15 43757 56 15 44104 26 15 44134 26 15 44452 26 15 44482 1 15 44484 7 15 44493 15 15 44801 25 15 44830 8 15 44843 13 15 45149 26 15 45178 8 15 45191 13 11 45380 9 15 45498 37 15 45541 11 11 45724 15 15 45846 37 15 45893 7 11 46070 18 18 46137 2 15 46194 40 15 46235 1 15 46242 6 11 46416 23 18 46483 4 15 46542 43 15 46592 4 11 46763 24 18 46831 4 15 46890 43 15 46940 4 11 47110 30 18 47175 9 15 47237 45 11 47457 31 18 47523 9 15 47584 46 11 47805 32 18 47870 9 15 47929 52 11 48152 34 18 48218 9 15 48277 52 11 48499 35 17 48558 4 18 48565 10 15 48625 54 11 48847 35 17 48904 7 18 48913 10 15 48973 54 11 49195 35 17 49251 8 18 49263 9 15 49321 54 11 49543 35 17 49598 9 18 49612 8 15 49669 43 15 49719 1 11 49890 36 17 49946 9 18 49961 6 15 50017 41 11 50237 37 17 50294 8 18 50309 6 15 50364 41 11 50585 37 17 50641 9 18 50657 6 15 50711 42 11 50932 40 17 50989 7 18 51005 6 15 51059 41 11 51279 41 17 51337 7 18 51354 5 15 51407 41 11 51626 42 18 51703 2 15 51755 40 11 51973 43 18 52051 2 15 52103 41 11 52320 2 11 52330 34 18 52399 2 15 52451 41 11 52679 33 15 52797 44 11 53027 33 15 53145 44 22 53212 2 11 53376 32 15 53493 44 22 53559 6 1 53633 7 11 53724 31 15 53841 44 22 53906 8 1 53978 11 11 54072 31 15 54189 45 22 54254 8 1 54324 15 8 54398 1 11 54420 32 15 54537 46 22 54602 9 1 54670 18 8 54746 2 9 54749 1 11 54769 31 15 54885 47 22 54951 9 22 54972 2 1 55016 21 8 55094 2 11 55117 31 15 55233 47 22 55298 11 22 55320 2 1 55362 24 8 55442 2 11 55465 31 15 55581 1 15 55583 45 22 55647 11 22 55667 5 1 55709 26 8 55790 2 11 55813 31 15 55929 47 22 55995 12 22 56015 5 1 56055 29 11 56162 32 15 56279 44 22 56344 14 22 56362 6 1 56403 30 11 56509 33 15 56627 45 22 56691 17 22 56709 7 1 56749 32 11 56858 33 15 56975 42 22 57039 26 1 57096 34 11 57206 33 15 57323 42 22 57387 27 1 57443 36 11 57555 33 15 57672 41 22 57735 27 1 57789 39 11 57904 32 15 58021 40 22 58083 27 1 58137 39 7 58226 4 11 58252 34 15 58369 39 22 58431 28 1 58484 40 7 58574 4 11 58604 31 15 58717 39 22 58779 28 1 58831 41 7 58922 4 11 58952 31 15 59065 39 22 59127 28 1 59178 14 1 59196 1 1 59198 23 7 59261 1 7 59263 13 11 59300 10 11 59311 22 15 59415 37 22 59475 28 1 59526 13 1 59546 23 7 59609 15 11 59646 1 11 59648 8 11 59657 1 11 59659 24 11 59725 4 15 59763 37 22 59823 28 1 59876 9 1 59900 16 7 59957 16 11 59994 1 11 59996 5 11 60007 26 11 60067 14 15 60111 31 15 60143 5 22 60173 26 1 60225 8 1 60248 16 7 60305 17 13 60334 1 11 60342 7 11 60355 26 11 60414 15 15 60459 31 15 60491 5 22 60521 26 1 60575 1 1 60599 13 7 60655 17 11 60688 1 11 60690 7 11 60703 28 11 60759 22 15 60807 29 15 60837 1 15 60839 3 22 60871 24 1 60947 13 7 61003 18 11 61036 1 11 61038 7 11 61051 28 11 61107 23 15 61155 29 15 61185 5 22 61219 23 2 61269 1 1 61296 12 7 61354 18 11 61384 1 11 61386 8 11 61399 1 11 61401 27 11 61452 28 15 61503 25 22 61567 23 2 61614 4 1 61644 12 7 61703 19 11 61732 10 11 61747 1 11 61749 27 11 61797 32 15 61851 25 22 61915 14 22 61930 8 2 61962 5 1 61993 11 7 62052 18 11 62082 6 11 62097 27 11 62143 37 15 62198 21 22 62265 9 22 62280 4 2 62310 5 1 62339 13 7 62400 19 11 62430 1 11 62432 1 14 62441 1 11 62447 25 11 62489 43 15 62546 11 22 62615 1 22 62617 1 22 62619 2 22 62631 1 2 62658 5 1 62687 12 7 62748 18 14 62789 1 11 62795 24 11 62837 47 15 62895 10 2 63007 3 1 63035 12 7 63096 17 14 63137 1 11 63143 24 11 63184 51 15 63243 9 2 63355 3 1 63383 11 7 63444 17 14 63485 1 16 63487 1 11 63491 22 11 63531 54 15 63593 7 2 63705 1 1 63722 1 1 63724 17 7 63793 14 14 63833 1 11 63839 20 11 63877 58 2 64053 1 1 64070 19 7 64141 14 14 64181 1 11 64187 20 11 64225 60 1 64416 19 7 64489 14 11 64536 18 11 64570 65 4 64753 1 1 64763 20 7 64836 15 11 64884 19 11 64917 68 1 65105 25 7 65184 14 11 65234 14 11 65264 71 1 65453 24 7 65532 14 11 65582 14 11 65611 73 21 65722 1 1 65801 18 1 65821 1 7 65879 14 11 65931 11 11 65960 72 21 66070 1 1 66149 18 7 66227 14 11 66279 11 11 66308 70 21 66416 3 1 66497 16 7 66573 15 11 66626 11 11 66657 71 21 66763 4 1 66846 15 7 66915 1 7 66917 19 11 66974 11 11 67006 72 21 67110 5 1 67194 14 7 67261 22 11 67322 10 11 67353 73 11 67427 1 21 67458 5 21 67467 3 1 67544 10 7 67606 25 11 67670 10 11 67701 75 21 67805 13 1 67896 2 7 67953 26 11 68018 10 11 68049 77 21 68153 13 7 68301 26 11 68367 8 11 68396 78 21 68502 11 7 68649 26 11 68715 8 11 68745 77 21 68850 11 7 68998 24 11 69063 7 11 69092 80 21 69201 8 7 69346 24 11 69412 6 11 69440 81 21 69549 8 7 69693 25 11 69760 6 11 69790 80 21 69899 4 7 70041 25 11 70108 6 11 70138 80 21 70247 4 7 70390 15 7 70406 1 7 70408 7 11 70456 8 11 70486 80 7 70738 14 7 70756 7 11 70804 10 11 70834 80 7 71086 14 7 71106 8 11 71152 11 11 71182 80 7 71434 13 7 71454 11 11 71500 11 11 71530 81 7 71782 13 7 71802 11 11 71848 11 11 71878 81 7 72129 14 7 72150 12 11 72195 13 11 72228 79 7 72476 15 7 72496 1 7 72498 12 11 72542 15 11 72576 80 7 72823 16 7 72844 14 11 72887 17 11 72924 81 7 73171 16 7 73190 17 11 73235 17 11 73272 81 7 73519 35 11 73579 18 11 73619 83 7 73868 33 11 73927 18 11 73967 83 7 74219 30 11 74273 19 11 74312 87 11 74423 6 7 74567 30 11 74619 20 11 74660 87 11 74767 11 6 74898 6 7 74917 28 11 74963 24 11 75006 88 11 75113 15 6 75245 8 7 75265 27 11 75305 30 11 75354 87 11 75459 17 6 75594 8 7 75615 24 11 75653 31 11 75700 89 11 75805 20 6 75942 9 7 75963 24 11 76000 35 11 76037 3 11 76046 92 11 76148 26 6 76289 9 7 76311 23 11 76348 41 11 76393 92 11 76493 30 6 76639 7 7 76659 1 7 76661 11 7 76674 6 11 76696 137 11 76838 35 11 76874 1 6 76987 7 7 77009 10 7 77024 3 11 77043 182 6 77335 5 7 77362 4 11 77396 178 6 77683 5 7 77710 4 11 77744 178 6 78030 3 7 78059 3 11 78092 179 6 78378 3 7 78407 3 11 78440 180 6 78719 10 7 78756 1 11 78789 180 6 79065 12 11 79137 181 6 79413 13 11 79486 181 6 79760 14 11 79834 181 6 80108 14 11 80183 180 6 80456 15 11 80532 179 6 80804 14 11 80880 181 6 81151 14 11 81229 181 6 81499 14 11 81577 182 6 81848 11 11 81924 183 6 82195 13 11 82272 183 6 82549 6 11 82618 185 6 82897 6 11 82967 7 11 82975 176 6 83247 1 11 83314 4 11 83323 176 11 83671 176 11 84017 178 11 84365 178 11 84711 180 11 85058 181 11 85404 183 11 85750 185 11 86096 187 11 86446 183 11 86795 182 11 87143 182 11 87491 182 11 87840 181 11 88188 180 11 88535 180 11 88883 180 11 89231 178 11 89578 179 11 89926 62 11 89989 115 11 90274 58 11 90340 110 11 90622 58 11 90688 110 11 90969 50 11 91036 108 11 91317 51 11 91384 108 11 91664 47 11 91732 107 11 92012 46 11 92079 108 11 92358 46 11 92427 21 11 92449 85 11 92706 44 11 92775 18 11 92798 84 11 93054 43 11 93122 17 11 93150 78 11 93402 42 11 93470 15 11 93500 74 11 93750 42 11 93817 16 11 93848 72 11 94102 37 11 94163 15 11 94196 1 11 94198 68 11 94450 37 11 94511 15 11 94544 1 11 94546 67 5 94722 1 5 94724 5 11 94798 37 11 94861 9 11 94894 63 5 95070 7 11 95146 38 11 95209 9 11 95242 63 5 95412 13 11 95495 36 11 95590 59 5 95760 13 11 95843 37 11 95938 59 5 96108 8 11 96192 26 11 96225 1 11 96284 1 11 96286 55 5 96456 7 11 96541 24 11 96632 56 11 96891 20 11 96969 1 11 96980 54 11 97239 19 11 97315 5 11 97328 54 3 97476 2 11 97589 17 11 97663 7 11 97678 50 3 97822 4 11 97937 17 11 98011 7 11 98026 48 3 98170 4 11 98285 17 11 98359 8 11 98374 48 3 98505 1 3 98517 6 11 98635 14 11 98709 6 11 98722 46 3 98851 5 3 98865 7 11 98983 15 11 99056 6 11 99070 46 3 99198 22 11 99334 10 11 99405 4 11 99416 47 3 99546 22 11 99682 11 11 99752 6 11 99764 47 3 99894 24 11 100033 8 11 100098 61 3 100242 24 11 100382 7 11 100445 62 3 100593 22 11 100733 3 11 100791 8 11 100803 53 3 100943 1 3 100945 1 3 100949 14 11 101139 8 11 101152 52 3 101300 12 11 101486 6 11 101504 48 3 101650 10 11 101835 3 11 101852 49 3 102000 9 11 102202 48 3 102350 8 11 102550 30 11 102591 9 11 102601 1 3 102698 8 11 102898 27 11 102939 11 3 103048 8 11 103248 22 11 103287 14 3 103396 9 11 103596 22 11 103635 15 3 103746 8 11 103944 20 11 103983 16 3 104094 9 11 104292 20 11 104331 17 3 104445 6 20 104610 3 11 104640 18 11 104678 21 3 104794 5 20 104958 3 11 104988 18 11 105026 21 3 105145 4 20 105306 2 11 105336 17 11 105374 23 3 105493 4 20 105653 3 11 105684 16 11 105722 25 20 106000 4 11 106032 16 11 106070 26 20 106348 4 11 106380 16 11 106419 5 11 106426 19 20 106696 4 11 106726 17 11 106768 1 11 106774 20 20 107044 4 11 107070 1 11 107074 17 11 107124 19 20 107392 4 11 107416 22 11 107472 20 20 107742 1 11 107762 10 11 107776 9 11 107820 22 20 108090 1 11 108109 12 11 108122 11 11 108168 22 11 108453 1 11 108455 12 11 108516 24 11 108801 15 11 108864 24 11 109140 22 11 109212 24 11 109486 24 11 109560 24 11 109832 1 11 109834 22 11 109908 26 11 110180 24 11 110256 5 11 110264 18 11 110528 1 11 110530 20 11 110606 2 11 110612 18 11 110878 18 11 110959 21 11 111228 16 11 111307 21 11 111334 7 11 111578 10 11 111655 6 11 111663 31 11 111927 8 11 112003 6 11 112011 31 11 112351 4 11 112360 32 11 112393 1 11 112699 3 11 112708 32 11 112741 1 11 113056 34 11 113404 34 11 113752 34 11 114100 34 11 114443 2 11 114447 35 11 114791 39 11 115139 39 11 115487 40 11 115835 40 11 116185 38 11 116533 37 11 116883 35 11 117231 35 11 117584 28 11 117933 27 11 118282 24 11 118632 20 11 118982 13 11 118996 1 11 119333 6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "submission_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-b0d42563-224f-48ce-a5b7-b55f58ff712b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>Epithelial</th>\n",
              "      <th>Lymphocyte</th>\n",
              "      <th>Neutrophil</th>\n",
              "      <th>Macrophage</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>slide_num</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>slide1</td>\n",
              "      <td>3 17920 4 3 18076 10 3 18233 11 15 18344 2 3 1...</td>\n",
              "      <td>1 31278 4 1 31433 7 1 31589 8 1 31745 10 1 319...</td>\n",
              "      <td>2 13135 3 2 13291 6 2 13447 7 2 13604 7 2 1376...</td>\n",
              "      <td>1 2010 5 1 2165 9 1 2319 13 1 2474 17 1 2629 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>slide2</td>\n",
              "      <td>4 2020 16 10 2682 13 4 2969 17 10 3630 16 4 39...</td>\n",
              "      <td>62 2112 2 83 2146 4 97 2175 15 125 2255 7 62 3...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>slide3</td>\n",
              "      <td>2 16490 2 2 17054 6 2 17620 8 2 18187 8 2 1875...</td>\n",
              "      <td>224 2642 5 264 2767 5 193 3172 3 224 3206 10 2...</td>\n",
              "      <td>15 132013 1 14 132016 2 14 132583 2 14 133150 ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>slide4</td>\n",
              "      <td>1 16187 1</td>\n",
              "      <td>0</td>\n",
              "      <td>1 2192 1 1 2197 2 1 2321 18 1 2453 23 1 2586 2...</td>\n",
              "      <td>2 11622 3 2 11756 3 1 12017 5 1 12151 5 1 12286 3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>slide5</td>\n",
              "      <td>265 22589 9 97 24057 7 265 24735 16 109 26260 ...</td>\n",
              "      <td>69 22707 1 105 23378 5 69 24856 5 105 25526 11...</td>\n",
              "      <td>10 331917 2 10 334065 9 10 336216 6 13 673908 ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b0d42563-224f-48ce-a5b7-b55f58ff712b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b0d42563-224f-48ce-a5b7-b55f58ff712b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b0d42563-224f-48ce-a5b7-b55f58ff712b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f26e9d25-d0f2-45ab-9855-95f099400402\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f26e9d25-d0f2-45ab-9855-95f099400402')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f26e9d25-d0f2-45ab-9855-95f099400402 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "          image_id                                         Epithelial  \\\n",
              "slide_num                                                               \n",
              "1           slide1  3 17920 4 3 18076 10 3 18233 11 15 18344 2 3 1...   \n",
              "2           slide2  4 2020 16 10 2682 13 4 2969 17 10 3630 16 4 39...   \n",
              "3           slide3  2 16490 2 2 17054 6 2 17620 8 2 18187 8 2 1875...   \n",
              "4           slide4                                          1 16187 1   \n",
              "5           slide5  265 22589 9 97 24057 7 265 24735 16 109 26260 ...   \n",
              "\n",
              "                                                  Lymphocyte  \\\n",
              "slide_num                                                      \n",
              "1          1 31278 4 1 31433 7 1 31589 8 1 31745 10 1 319...   \n",
              "2          62 2112 2 83 2146 4 97 2175 15 125 2255 7 62 3...   \n",
              "3          224 2642 5 264 2767 5 193 3172 3 224 3206 10 2...   \n",
              "4                                                          0   \n",
              "5          69 22707 1 105 23378 5 69 24856 5 105 25526 11...   \n",
              "\n",
              "                                                  Neutrophil  \\\n",
              "slide_num                                                      \n",
              "1          2 13135 3 2 13291 6 2 13447 7 2 13604 7 2 1376...   \n",
              "2                                                          0   \n",
              "3          15 132013 1 14 132016 2 14 132583 2 14 133150 ...   \n",
              "4          1 2192 1 1 2197 2 1 2321 18 1 2453 23 1 2586 2...   \n",
              "5          10 331917 2 10 334065 9 10 336216 6 13 673908 ...   \n",
              "\n",
              "                                                  Macrophage  \n",
              "slide_num                                                     \n",
              "1          1 2010 5 1 2165 9 1 2319 13 1 2474 17 1 2629 2...  \n",
              "2                                                          0  \n",
              "3                                                          0  \n",
              "4          2 11622 3 2 11756 3 1 12017 5 1 12151 5 1 12286 3  \n",
              "5                                                          0  "
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"\\nGenerating predictions...\")\n",
        "submission_df = predict_test_set(model, TEST_DIR, DEVICE)\n",
        "\n",
        "# Extract the number at the end of image_id coulmn\n",
        "submission_df['slide_num'] = submission_df['image_id'].str.extract(r'(\\d+)$')\n",
        "submission_df['slide_num'] = submission_df['slide_num'].astype(int)\n",
        "\n",
        "# Set slide number as index column and sort by it\n",
        "submission_df.set_index('slide_num', inplace=True)\n",
        "submission_df.sort_index(inplace=True)\n",
        "\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "print(f\"\\nâœ… Submission saved: submission.csv\")\n",
        "print(f\"Shape: {submission_df.shape}\")\n",
        "print(\"\\nSample rows:\")\n",
        "submission_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjlGFoM2-qp0",
        "outputId": "e167fef7-e7d4-49e0-b6e0-bb9228477483"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 1.9G\n",
            "-rw-r--r-- 1 root root 263M Oct 28 03:01 best_model.pth\n",
            "-rw-r--r-- 1 root root 312M Oct 18 00:23 cell-segmentation-cs-gy-6643.zip\n",
            "drwxr-xr-x 4 root root 4.0K Oct 28 01:15 data_folder\n",
            "-rw-r--r-- 1 root root 263M Oct 28 01:38 fold_1_model.pth\n",
            "-rw-r--r-- 1 root root 263M Oct 28 02:00 fold_2_model.pth\n",
            "-rw-r--r-- 1 root root 263M Oct 28 02:21 fold_3_model.pth\n",
            "-rw-r--r-- 1 root root 263M Oct 28 02:43 fold_4_model.pth\n",
            "-rw-r--r-- 1 root root 263M Oct 28 03:03 fold_5_model.pth\n",
            "drwxr-xr-x 1 root root 4.0K Oct 24 13:37 sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls -lh\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "4V6kwBQtuwv8",
        "outputId": "4e1e4c14-fa5d-4807-8ea9-a4779be86931"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_83d5640d-eb41-4c7e-803b-e4c507663d58\", \"submission.csv\", 2256277)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('submission.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "jcP7Ca7zxgOT",
        "mrPb6o3ExgLB",
        "1bpUakE7xgIJ",
        "_rhai-fixgFL"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
